{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from analysis import Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UQC Raw vs Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uqc_policies_paths = [\n",
    "    \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits_raw_contiguous\",\n",
    "    \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits_raw_parity\",\n",
    "    \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "uqc_model_raw_contiguous = Analysis(uqc_policies_paths[0])\n",
    "uqc_model_raw_parity = Analysis(uqc_policies_paths[1])\n",
    "uqc_model = Analysis(uqc_policies_paths[2])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "uqc_model_raw_contiguous_rewards = uqc_model_raw_contiguous.get_moving_average(window_size=10)\n",
    "uqc_model_raw_parity_rewards = uqc_model_raw_parity.get_moving_average(window_size=10)\n",
    "uqc_model_rewards = uqc_model.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "uqc_model_raw_contiguous_rewards_mean = np.mean(uqc_model_raw_contiguous_rewards, axis=0)\n",
    "uqc_model_raw_parity_rewards_mean = np.mean(uqc_model_raw_parity_rewards, axis=0)\n",
    "uqc_model_rewards_mean = np.mean(uqc_model_rewards, axis=0)\n",
    "\n",
    "uqc_model_raw_contiguous_rewards_std = np.std(uqc_model_raw_contiguous_rewards, axis=0)\n",
    "uqc_model_raw_parity_rewards_std = np.std(uqc_model_raw_parity_rewards, axis=0)\n",
    "uqc_model_rewards_std = np.std(uqc_model_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "uqc_model_raw_contiguous_norm_grads, uqc_model_raw_contiguous_variance_grads = uqc_model_raw_contiguous.compute_norm_and_variance()\n",
    "uqc_model_raw_parity_norm_grads, uqc_model_raw_parity_variance_grads = uqc_model_raw_parity.compute_norm_and_variance()\n",
    "uqc_model_norm_grads, uqc_model_variance_grads = uqc_model.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "plt.plot(uqc_model_raw_contiguous_rewards_mean, color=\"red\", label=\"Raw Contiguous\")\n",
    "plt.plot(uqc_model_raw_parity_rewards_mean, color=\"blue\", label=\"Raw Parity\")\n",
    "plt.plot(uqc_model_rewards_mean, color=\"green\", label=\"Softmax\")\n",
    "plt.fill_between(np.arange(len(uqc_model_raw_contiguous_rewards_mean)), \n",
    "                    np.clip(uqc_model_raw_contiguous_rewards_mean - uqc_model_raw_contiguous_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(uqc_model_raw_contiguous_rewards_mean + uqc_model_raw_contiguous_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "plt.fill_between(np.arange(len(uqc_model_raw_parity_rewards_mean)), \n",
    "                    np.clip(uqc_model_raw_parity_rewards_mean - uqc_model_raw_parity_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(uqc_model_raw_parity_rewards_mean + uqc_model_raw_parity_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "plt.fill_between(np.arange(len(uqc_model_rewards_mean)), \n",
    "                    np.clip(uqc_model_rewards_mean - uqc_model_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(uqc_model_rewards_mean + uqc_model_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.ylim(0,500)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"../../../../data/CartPole-v1/UQC/uqc_policies_cartpole.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uqc_policies_paths = [\n",
    "    \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_4qubits_raw_contiguous\",\n",
    "    \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_4qubits\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "uqc_model_raw_contiguous = Analysis(uqc_policies_paths[0])\n",
    "uqc_model = Analysis(uqc_policies_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "uqc_model_raw_contiguous_rewards = uqc_model_raw_contiguous.get_moving_average(window_size=10)\n",
    "uqc_model_rewards = uqc_model.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "uqc_model_raw_contiguous_rewards_mean = np.mean(uqc_model_raw_contiguous_rewards, axis=0)\n",
    "uqc_model_rewards_mean = np.mean(uqc_model_rewards, axis=0)\n",
    "\n",
    "uqc_model_raw_contiguous_rewards_std = np.std(uqc_model_raw_contiguous_rewards, axis=0)\n",
    "uqc_model_rewards_std = np.std(uqc_model_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "uqc_model_raw_contiguous_norm_grads, uqc_model_raw_contiguous_variance_grads = uqc_model_raw_contiguous.compute_norm_and_variance()\n",
    "uqc_model_norm_grads, uqc_model_variance_grads = uqc_model.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "plt.plot(uqc_model_raw_contiguous_rewards_mean, color=\"red\", label=\"Raw Contiguous\")\n",
    "plt.plot(uqc_model_rewards_mean, color=\"blue\", label=\"Softmax\")\n",
    "plt.fill_between(np.arange(len(uqc_model_raw_contiguous_rewards_mean)), \n",
    "                    np.clip(uqc_model_raw_contiguous_rewards_mean - uqc_model_raw_contiguous_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(uqc_model_raw_contiguous_rewards_mean + uqc_model_raw_contiguous_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "plt.fill_between(np.arange(len(uqc_model_rewards_mean)), \n",
    "                    np.clip(uqc_model_rewards_mean - uqc_model_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(uqc_model_rewards_mean + uqc_model_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.ylim(-500,0)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/UQC/uqc_policies_acrobot.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UQC 1-4 qubit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UQC_FullEnc_paths= [ \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_1qubits\",\n",
    "        \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_2qubits\",\n",
    "        \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_2qubits_no_entangle\",\n",
    "        \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits\",\n",
    "        \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits_no_entangle\"]\n",
    "\n",
    "UQC_FullEnc_1qubits = Analysis(UQC_FullEnc_paths[0])\n",
    "UQC_FullEnc_2qubits = Analysis(UQC_FullEnc_paths[1])\n",
    "UQC_FullEnc_2qubits_no_entangle = Analysis(UQC_FullEnc_paths[2])\n",
    "UQC_FullEnc_4qubits = Analysis(UQC_FullEnc_paths[3])\n",
    "UQC_FullEnc_4qubits_no_entangle = Analysis(UQC_FullEnc_paths[4])\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards = UQC_FullEnc_1qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_2qubits_rewards = UQC_FullEnc_2qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_2qubits_no_entangle_rewards = UQC_FullEnc_2qubits_no_entangle.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_4qubits_rewards = UQC_FullEnc_4qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_4qubits_no_entangle_rewards = UQC_FullEnc_4qubits_no_entangle.get_moving_average(window_size=10)\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards_mean = np.mean(UQC_FullEnc_1qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_rewards_mean = np.mean(UQC_FullEnc_2qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_no_entangle_rewards_mean = np.mean(UQC_FullEnc_2qubits_no_entangle_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_rewards_mean = np.mean(UQC_FullEnc_4qubits_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_no_entangle_rewards_mean = np.mean(UQC_FullEnc_4qubits_no_entangle_rewards, axis=0)\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards_std = np.std(UQC_FullEnc_1qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_rewards_std = np.std(UQC_FullEnc_2qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_no_entangle_rewards_std = np.std(UQC_FullEnc_2qubits_no_entangle_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_rewards_std = np.std(UQC_FullEnc_4qubits_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_no_entangle_std = np.std(UQC_FullEnc_4qubits_no_entangle_rewards, axis=0)\n",
    "\n",
    "\n",
    "UQC_FullEnc_1qubits_norm_grads,             UQC_FullEnc_1qubits_variance_grads = UQC_FullEnc_1qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_2qubits_norm_grads,             UQC_FullEnc_2qubits_variance_grads = UQC_FullEnc_2qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_2qubits_no_entangle_norm_grads, UQC_FullEnc_2qubits_no_entangle_variance_grads = UQC_FullEnc_2qubits_no_entangle.compute_norm_and_variance()\n",
    "UQC_FullEnc_4qubits_norm_grads,             UQC_FullEnc_4qubits_variance_grads = UQC_FullEnc_4qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_4qubits_no_entangle_norm_grads, UQC_FullEnc_4qubits_no_entangle_variance_grads = UQC_FullEnc_4qubits_no_entangle.compute_norm_and_variance()\n",
    "\n",
    "\n",
    "UQC_FullEnc_1qubits_runtime = sum(map(sum, UQC_FullEnc_1qubits.get_runtime())) / len(UQC_FullEnc_1qubits.get_runtime())/60\n",
    "UQC_FullEnc_2qubits_runtime = sum(map(sum, UQC_FullEnc_2qubits.get_runtime())) / len(UQC_FullEnc_2qubits.get_runtime())/60\n",
    "UQC_FullEnc_2qubits_no_entangle_runtime = sum(map(sum, UQC_FullEnc_2qubits_no_entangle.get_runtime())) / len(UQC_FullEnc_2qubits_no_entangle.get_runtime())/60\n",
    "UQC_FullEnc_4qubits_runtime = sum(map(sum, UQC_FullEnc_4qubits.get_runtime())) / len(UQC_FullEnc_4qubits.get_runtime())/60\n",
    "UQC_FullEnc_4qubits_no_entangle_runtime = sum(map(sum, UQC_FullEnc_4qubits_no_entangle.get_runtime())) / len(UQC_FullEnc_4qubits_no_entangle.get_runtime())/60\n",
    "\n",
    "\n",
    "\n",
    "UQC_PartialEnc_paths= [\"../../../../data/CartPole-v1/UQC/UQC_PartialEnc_2qubits\",\n",
    "                        \"../../../../data/CartPole-v1/UQC/UQC_PartialEnc_2qubits_no_entangle\",\n",
    "                        \"../../../../data/CartPole-v1/UQC/UQC_PartialEnc_4qubits\",\n",
    "                        \"../../../../data/CartPole-v1/UQC/UQC_PartialEnc_4qubits_no_entangle\"]\n",
    "\n",
    "UQC_PartialEnc_2qubits = Analysis(UQC_PartialEnc_paths[0])\n",
    "UQC_PartialEnc_2qubits_no_entangle = Analysis(UQC_PartialEnc_paths[1])\n",
    "UQC_PartialEnc_4qubits = Analysis(UQC_PartialEnc_paths[2])\n",
    "UQC_PartialEnc_4qubits_no_entangle = Analysis(UQC_PartialEnc_paths[3])\n",
    "\n",
    "UQC_PartialEnc_2qubits_rewards = UQC_PartialEnc_2qubits.get_moving_average(window_size=10)\n",
    "UQC_PartialEnc_2qubits_no_entangle_rewards = UQC_PartialEnc_2qubits_no_entangle.get_moving_average(window_size=10)\n",
    "UQC_PartialEnc_4qubits_rewards = UQC_PartialEnc_4qubits.get_moving_average(window_size=10)\n",
    "UQC_PartialEnc_4qubits_no_entangle_rewards = UQC_PartialEnc_4qubits_no_entangle.get_moving_average(window_size=10)\n",
    "\n",
    "UQC_PartialEnc_2qubits_rewards_mean = np.mean(UQC_PartialEnc_2qubits_rewards, axis=0)\n",
    "UQC_PartialEnc_2qubits_no_entangle_rewards_mean = np.mean(UQC_PartialEnc_2qubits_no_entangle_rewards, axis=0)\n",
    "UQC_PartialEnc_4qubits_rewards_mean = np.mean(UQC_PartialEnc_4qubits_rewards, axis=0)\n",
    "UQC_PartialEnc_4qubits_no_entangle_rewards_mean = np.mean(UQC_PartialEnc_4qubits_no_entangle_rewards, axis=0)\n",
    "\n",
    "UQC_PartialEnc_2qubits_rewards_std = np.std(UQC_PartialEnc_2qubits_rewards, axis=0)\n",
    "UQC_PartialEnc_2qubits_no_entangle_rewards_std = np.std(UQC_PartialEnc_2qubits_no_entangle_rewards, axis=0)\n",
    "UQC_PartialEnc_4qubits_rewards_std = np.std(UQC_PartialEnc_4qubits_rewards, axis=0)\n",
    "UQC_PartialEnc_4qubits_no_entangle_std = np.std(UQC_PartialEnc_4qubits_no_entangle_rewards, axis=0)\n",
    "\n",
    "UQC_PartialEnc_2qubits_norm_grads,             UQC_PartialEnc_2qubits_variance_grads = UQC_PartialEnc_2qubits.compute_norm_and_variance()\n",
    "UQC_PartialEnc_2qubits_no_entangle_norm_grads, UQC_PartialEnc_2qubits_no_entangle_variance_grads = UQC_PartialEnc_2qubits_no_entangle.compute_norm_and_variance()\n",
    "UQC_PartialEnc_4qubits_norm_grads,             UQC_PartialEnc_4qubits_variance_grads = UQC_PartialEnc_4qubits.compute_norm_and_variance()\n",
    "UQC_PartialEnc_4qubits_no_entangle_norm_grads, UQC_PartialEnc_4qubits_no_entangle_variance_grads = UQC_PartialEnc_4qubits_no_entangle.compute_norm_and_variance()\n",
    "\n",
    "UQC_PartialEnc_2qubits_runtime = sum(map(sum, UQC_PartialEnc_2qubits.get_runtime())) / len(UQC_PartialEnc_2qubits.get_runtime())/60\n",
    "UQC_PartialEnc_2qubits_no_entangle_runtime = sum(map(sum, UQC_PartialEnc_2qubits_no_entangle.get_runtime())) / len(UQC_PartialEnc_2qubits_no_entangle.get_runtime())/60\n",
    "UQC_PartialEnc_4qubits_runtime = sum(map(sum, UQC_PartialEnc_4qubits.get_runtime())) / len(UQC_PartialEnc_4qubits.get_runtime())/60\n",
    "UQC_PartialEnc_4qubits_no_entangle_runtime = sum(map(sum, UQC_PartialEnc_4qubits_no_entangle.get_runtime())) / len(UQC_PartialEnc_4qubits_no_entangle.get_runtime())/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "axs[0].plot(UQC_FullEnc_1qubits_rewards_mean, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_2qubits_rewards_mean, color=\"green\", label=\"Two-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_2qubits_no_entangle_rewards_mean, color=\"blue\", label=\"Two-Qubit UQC w/o Entanglement\")\n",
    "axs[0].plot(UQC_FullEnc_4qubits_rewards_mean, color=\"purple\", label=\"Four-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_4qubits_no_entangle_rewards_mean, color=\"orange\", label=\"Four-Qubit UQC w/o Entanglement\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_1qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_1qubits_rewards_mean - UQC_FullEnc_1qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_1qubits_rewards_mean + UQC_FullEnc_1qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_2qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_2qubits_rewards_mean - UQC_FullEnc_2qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_2qubits_rewards_mean + UQC_FullEnc_2qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_2qubits_no_entangle_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_2qubits_no_entangle_rewards_mean - UQC_FullEnc_2qubits_no_entangle_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_2qubits_no_entangle_rewards_mean + UQC_FullEnc_2qubits_no_entangle_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_4qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_4qubits_rewards_mean - UQC_FullEnc_4qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_4qubits_rewards_mean + UQC_FullEnc_4qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"purple\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_4qubits_no_entangle_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_4qubits_no_entangle_rewards_mean - UQC_FullEnc_4qubits_no_entangle_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_4qubits_no_entangle_rewards_mean + UQC_FullEnc_4qubits_no_entangle_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"orange\")\n",
    "axs[0].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[0].legend(fontsize = 12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "\n",
    "\n",
    "axs[1].plot(UQC_PartialEnc_2qubits_rewards_mean, color=\"green\", label=\"Two-Qubit UQC\")\n",
    "axs[1].plot(UQC_PartialEnc_2qubits_no_entangle_rewards_mean, color=\"blue\", label=\"Two-Qubit UQC w/o Entanglement\")\n",
    "axs[1].plot(UQC_PartialEnc_4qubits_rewards_mean, color=\"purple\", label=\"Four-Qubit\")\n",
    "axs[1].plot(UQC_PartialEnc_4qubits_no_entangle_rewards_mean, color=\"orange\", label=\"Four-Qubit w/o Entanglement\")\n",
    "axs[1].fill_between(np.arange(len(UQC_PartialEnc_2qubits_rewards_mean)), \n",
    "                    np.clip(UQC_PartialEnc_2qubits_rewards_mean - UQC_PartialEnc_2qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_PartialEnc_2qubits_rewards_mean + UQC_PartialEnc_2qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "axs[1].fill_between(np.arange(len(UQC_PartialEnc_2qubits_no_entangle_rewards_mean)), \n",
    "                    np.clip(UQC_PartialEnc_2qubits_no_entangle_rewards_mean - UQC_PartialEnc_2qubits_no_entangle_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_PartialEnc_2qubits_no_entangle_rewards_mean + UQC_PartialEnc_2qubits_no_entangle_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "axs[1].fill_between(np.arange(len(UQC_PartialEnc_4qubits_rewards_mean)), \n",
    "                    np.clip(UQC_PartialEnc_4qubits_rewards_mean - UQC_PartialEnc_4qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_PartialEnc_4qubits_rewards_mean + UQC_PartialEnc_4qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"purple\")\n",
    "axs[1].fill_between(np.arange(len(UQC_PartialEnc_4qubits_no_entangle_rewards_mean)), \n",
    "                    np.clip(UQC_PartialEnc_4qubits_no_entangle_rewards_mean - UQC_PartialEnc_4qubits_no_entangle_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_PartialEnc_4qubits_no_entangle_rewards_mean + UQC_PartialEnc_4qubits_no_entangle_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"orange\")\n",
    "axs[1].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[1].legend(fontsize = 12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/UQC/uqc_encode_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Single-Qubit UQC\", \"Two-Qubit UQC\", \"Two-Qubit UQC w/o Entanglement\", \"Four-Qubit UQC\", \"Four-Qubit UQC w/o Entanglement\"]\n",
    "runtimes = [UQC_FullEnc_1qubits_runtime, UQC_FullEnc_2qubits_runtime, UQC_FullEnc_2qubits_no_entangle_runtime, \n",
    "            UQC_FullEnc_4qubits_runtime, UQC_FullEnc_4qubits_no_entangle_runtime]\n",
    "\n",
    "# Create a 1x3 grid of subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot mean gradient norms for Full Encoding in the first subplot (top-left)\n",
    "axs[0].plot(UQC_FullEnc_1qubits_norm_grads, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_2qubits_norm_grads, color=\"green\", label=\"Two-Qubit Full UQC\")\n",
    "axs[0].plot(UQC_PartialEnc_2qubits_norm_grads, color=\"blue\", label=\"Two-Qubit Partial UQC\")\n",
    "axs[0].plot(UQC_FullEnc_4qubits_norm_grads, color=\"purple\", label=\"Four-Qubit Full UQC\")\n",
    "axs[0].plot(UQC_PartialEnc_4qubits_norm_grads, color=\"orange\", label=\"Four-Qubit Partial UQC\")\n",
    "axs[0].set_xlabel(\"Training Batch\", fontsize=12)\n",
    "axs[0].set_ylabel(\"Mean Gradient Norm\", fontsize=12)\n",
    "axs[0].legend(fontsize=12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot variance of gradient norms for Full Encoding in the second subplot (top-right)\n",
    "axs[1].plot(UQC_FullEnc_1qubits_variance_grads, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_2qubits_variance_grads, color=\"green\", label=\"Two-Qubit Full UQC\")\n",
    "axs[1].plot(UQC_PartialEnc_2qubits_variance_grads, color=\"blue\", label=\"Two-Qubit Partial UQC\")\n",
    "axs[1].plot(UQC_FullEnc_4qubits_variance_grads, color=\"purple\", label=\"Four-Qubit Full UQC\")\n",
    "axs[1].plot(UQC_PartialEnc_4qubits_variance_grads, color=\"orange\", label=\"Four-Qubit Partial UQC\")\n",
    "axs[1].set_xlabel(\"Training Batch\", fontsize=12)\n",
    "axs[1].set_ylabel(\"Variance of the Gradient Norm\", fontsize=12)\n",
    "axs[1].legend(fontsize=12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Automatically adjust layout for better fit\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/UQC/uqc_gradients_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UQC_FullEnc_paths= [ \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_1qubits\",\n",
    "        \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_2qubits\",\n",
    "        \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_2qubits_no_entangle\",\n",
    "        \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_4qubits\",\n",
    "        \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_4qubits_no_entangle\"]\n",
    "\n",
    "UQC_FullEnc_1qubits = Analysis(UQC_FullEnc_paths[0])\n",
    "UQC_FullEnc_2qubits = Analysis(UQC_FullEnc_paths[1])\n",
    "UQC_FullEnc_2qubits_no_entangle = Analysis(UQC_FullEnc_paths[2])\n",
    "UQC_FullEnc_4qubits = Analysis(UQC_FullEnc_paths[3])\n",
    "UQC_FullEnc_4qubits_no_entangle = Analysis(UQC_FullEnc_paths[4])\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards = UQC_FullEnc_1qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_2qubits_rewards = UQC_FullEnc_2qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_2qubits_no_entangle_rewards = UQC_FullEnc_2qubits_no_entangle.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_4qubits_rewards = UQC_FullEnc_4qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_4qubits_no_entangle_rewards = UQC_FullEnc_4qubits_no_entangle.get_moving_average(window_size=10)\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards_mean = np.mean(UQC_FullEnc_1qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_rewards_mean = np.mean(UQC_FullEnc_2qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_no_entangle_rewards_mean = np.mean(UQC_FullEnc_2qubits_no_entangle_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_rewards_mean = np.mean(UQC_FullEnc_4qubits_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_no_entangle_rewards_mean = np.mean(UQC_FullEnc_4qubits_no_entangle_rewards, axis=0)\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards_std = np.std(UQC_FullEnc_1qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_rewards_std = np.std(UQC_FullEnc_2qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_no_entangle_rewards_std = np.std(UQC_FullEnc_2qubits_no_entangle_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_rewards_std = np.std(UQC_FullEnc_4qubits_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_no_entangle_std = np.std(UQC_FullEnc_4qubits_no_entangle_rewards, axis=0)\n",
    "\n",
    "\n",
    "UQC_FullEnc_1qubits_norm_grads,             UQC_FullEnc_1qubits_variance_grads = UQC_FullEnc_1qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_2qubits_norm_grads,             UQC_FullEnc_2qubits_variance_grads = UQC_FullEnc_2qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_2qubits_no_entangle_norm_grads, UQC_FullEnc_2qubits_no_entangle_variance_grads = UQC_FullEnc_2qubits_no_entangle.compute_norm_and_variance()\n",
    "UQC_FullEnc_4qubits_norm_grads,             UQC_FullEnc_4qubits_variance_grads = UQC_FullEnc_4qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_4qubits_no_entangle_norm_grads, UQC_FullEnc_4qubits_no_entangle_variance_grads = UQC_FullEnc_4qubits_no_entangle.compute_norm_and_variance()\n",
    "\n",
    "\n",
    "UQC_FullEnc_1qubits_runtime = sum(map(sum, UQC_FullEnc_1qubits.get_runtime())) / len(UQC_FullEnc_1qubits.get_runtime())/60\n",
    "UQC_FullEnc_2qubits_runtime = sum(map(sum, UQC_FullEnc_2qubits.get_runtime())) / len(UQC_FullEnc_2qubits.get_runtime())/60\n",
    "UQC_FullEnc_2qubits_no_entangle_runtime = sum(map(sum, UQC_FullEnc_2qubits_no_entangle.get_runtime())) / len(UQC_FullEnc_2qubits_no_entangle.get_runtime())/60\n",
    "UQC_FullEnc_4qubits_runtime = sum(map(sum, UQC_FullEnc_4qubits.get_runtime())) / len(UQC_FullEnc_4qubits.get_runtime())/60\n",
    "UQC_FullEnc_4qubits_no_entangle_runtime = sum(map(sum, UQC_FullEnc_4qubits_no_entangle.get_runtime())) / len(UQC_FullEnc_4qubits_no_entangle.get_runtime())/60\n",
    "\n",
    "\n",
    "\n",
    "UQC_PartialEnc_paths= [\"../../../../data/Acrobot-v1/UQC/UQC_PartialEnc_2qubits\",\n",
    "                        \"../../../../data/Acrobot-v1/UQC/UQC_PartialEnc_2qubits_no_entangle\",\n",
    "                        \"../../../../data/Acrobot-v1/UQC/UQC_PartialEnc_4qubits\",\n",
    "                        \"../../../../data/Acrobot-v1/UQC/UQC_PartialEnc_4qubits_no_entangle\"]\n",
    "\n",
    "UQC_PartialEnc_2qubits = Analysis(UQC_PartialEnc_paths[0])\n",
    "UQC_PartialEnc_2qubits_no_entangle = Analysis(UQC_PartialEnc_paths[1])\n",
    "UQC_PartialEnc_4qubits = Analysis(UQC_PartialEnc_paths[2])\n",
    "UQC_PartialEnc_4qubits_no_entangle = Analysis(UQC_PartialEnc_paths[3])\n",
    "\n",
    "UQC_PartialEnc_2qubits_rewards = UQC_PartialEnc_2qubits.get_moving_average(window_size=10)\n",
    "UQC_PartialEnc_2qubits_no_entangle_rewards = UQC_PartialEnc_2qubits_no_entangle.get_moving_average(window_size=10)\n",
    "UQC_PartialEnc_4qubits_rewards = UQC_PartialEnc_4qubits.get_moving_average(window_size=10)\n",
    "UQC_PartialEnc_4qubits_no_entangle_rewards = UQC_PartialEnc_4qubits_no_entangle.get_moving_average(window_size=10)\n",
    "\n",
    "UQC_PartialEnc_2qubits_rewards_mean = np.mean(UQC_PartialEnc_2qubits_rewards, axis=0)\n",
    "UQC_PartialEnc_2qubits_no_entangle_rewards_mean = np.mean(UQC_PartialEnc_2qubits_no_entangle_rewards, axis=0)\n",
    "UQC_PartialEnc_4qubits_rewards_mean = np.mean(UQC_PartialEnc_4qubits_rewards, axis=0)\n",
    "UQC_PartialEnc_4qubits_no_entangle_rewards_mean = np.mean(UQC_PartialEnc_4qubits_no_entangle_rewards, axis=0)\n",
    "\n",
    "UQC_PartialEnc_2qubits_rewards_std = np.std(UQC_PartialEnc_2qubits_rewards, axis=0)\n",
    "UQC_PartialEnc_2qubits_no_entangle_rewards_std = np.std(UQC_PartialEnc_2qubits_no_entangle_rewards, axis=0)\n",
    "UQC_PartialEnc_4qubits_rewards_std = np.std(UQC_PartialEnc_4qubits_rewards, axis=0)\n",
    "UQC_PartialEnc_4qubits_no_entangle_std = np.std(UQC_PartialEnc_4qubits_no_entangle_rewards, axis=0)\n",
    "\n",
    "UQC_PartialEnc_2qubits_norm_grads,             UQC_PartialEnc_2qubits_variance_grads = UQC_PartialEnc_2qubits.compute_norm_and_variance()\n",
    "UQC_PartialEnc_2qubits_no_entangle_norm_grads, UQC_PartialEnc_2qubits_no_entangle_variance_grads = UQC_PartialEnc_2qubits_no_entangle.compute_norm_and_variance()\n",
    "UQC_PartialEnc_4qubits_norm_grads,             UQC_PartialEnc_4qubits_variance_grads = UQC_PartialEnc_4qubits.compute_norm_and_variance()\n",
    "UQC_PartialEnc_4qubits_no_entangle_norm_grads, UQC_PartialEnc_4qubits_no_entangle_variance_grads = UQC_PartialEnc_4qubits_no_entangle.compute_norm_and_variance()\n",
    "\n",
    "UQC_PartialEnc_2qubits_runtime = sum(map(sum, UQC_PartialEnc_2qubits.get_runtime())) / len(UQC_PartialEnc_2qubits.get_runtime())/60\n",
    "UQC_PartialEnc_2qubits_no_entangle_runtime = sum(map(sum, UQC_PartialEnc_2qubits_no_entangle.get_runtime())) / len(UQC_PartialEnc_2qubits_no_entangle.get_runtime())/60\n",
    "UQC_PartialEnc_4qubits_runtime = sum(map(sum, UQC_PartialEnc_4qubits.get_runtime())) / len(UQC_PartialEnc_4qubits.get_runtime())/60\n",
    "UQC_PartialEnc_4qubits_no_entangle_runtime = sum(map(sum, UQC_PartialEnc_4qubits_no_entangle.get_runtime())) / len(UQC_PartialEnc_4qubits_no_entangle.get_runtime())/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "axs[0].plot(UQC_FullEnc_1qubits_rewards_mean, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_2qubits_rewards_mean, color=\"green\", label=\"Two-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_2qubits_no_entangle_rewards_mean, color=\"blue\", label=\"Two-Qubit UQC w/o Entanglement\")\n",
    "axs[0].plot(UQC_FullEnc_4qubits_rewards_mean, color=\"purple\", label=\"Four-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_4qubits_no_entangle_rewards_mean, color=\"orange\", label=\"Four-Qubit UQC w/o Entanglement\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_1qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_1qubits_rewards_mean - UQC_FullEnc_1qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_1qubits_rewards_mean + UQC_FullEnc_1qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_2qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_2qubits_rewards_mean - UQC_FullEnc_2qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_2qubits_rewards_mean + UQC_FullEnc_2qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_2qubits_no_entangle_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_2qubits_no_entangle_rewards_mean - UQC_FullEnc_2qubits_no_entangle_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_2qubits_no_entangle_rewards_mean + UQC_FullEnc_2qubits_no_entangle_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_4qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_4qubits_rewards_mean - UQC_FullEnc_4qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_4qubits_rewards_mean + UQC_FullEnc_4qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"purple\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_4qubits_no_entangle_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_4qubits_no_entangle_rewards_mean - UQC_FullEnc_4qubits_no_entangle_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_4qubits_no_entangle_rewards_mean + UQC_FullEnc_4qubits_no_entangle_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"orange\")\n",
    "axs[0].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[0].set_ylim(-500,0)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].legend(fontsize=12, loc = 'upper left')\n",
    "axs[0].grid(True)\n",
    "\n",
    "\n",
    "\n",
    "axs[1].plot(UQC_PartialEnc_2qubits_rewards_mean, color=\"green\", label=\"Two-Qubit UQC\")\n",
    "axs[1].plot(UQC_PartialEnc_2qubits_no_entangle_rewards_mean, color=\"blue\", label=\"Two-Qubit UQC w/o Entanglement\")\n",
    "axs[1].plot(UQC_PartialEnc_4qubits_rewards_mean, color=\"purple\", label=\"Four-Qubit UQC\")\n",
    "axs[1].plot(UQC_PartialEnc_4qubits_no_entangle_rewards_mean, color=\"orange\", label=\"Four-Qubit UQC w/o Entanglement\")\n",
    "axs[1].fill_between(np.arange(len(UQC_PartialEnc_2qubits_rewards_mean)), \n",
    "                    np.clip(UQC_PartialEnc_2qubits_rewards_mean - UQC_PartialEnc_2qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_PartialEnc_2qubits_rewards_mean + UQC_PartialEnc_2qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "axs[1].fill_between(np.arange(len(UQC_PartialEnc_2qubits_no_entangle_rewards_mean)), \n",
    "                    np.clip(UQC_PartialEnc_2qubits_no_entangle_rewards_mean - UQC_PartialEnc_2qubits_no_entangle_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_PartialEnc_2qubits_no_entangle_rewards_mean + UQC_PartialEnc_2qubits_no_entangle_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "axs[1].fill_between(np.arange(len(UQC_PartialEnc_4qubits_rewards_mean)), \n",
    "                    np.clip(UQC_PartialEnc_4qubits_rewards_mean - UQC_PartialEnc_4qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_PartialEnc_4qubits_rewards_mean + UQC_PartialEnc_4qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"purple\")\n",
    "axs[1].fill_between(np.arange(len(UQC_PartialEnc_4qubits_no_entangle_rewards_mean)), \n",
    "                    np.clip(UQC_PartialEnc_4qubits_no_entangle_rewards_mean - UQC_PartialEnc_4qubits_no_entangle_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_PartialEnc_4qubits_no_entangle_rewards_mean + UQC_PartialEnc_4qubits_no_entangle_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"orange\")\n",
    "axs[1].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[1].set_ylim(-500,0)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].legend(fontsize=12,loc='upper left')\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/UQC/uqc_encode_acrobot.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Single-Qubit UQC\", \"Two-Qubit UQC\", \"Two-Qubit UQC w/o Entanglement\", \"Four-Qubit UQC\", \"Four-Qubit UQC w/o Entanglement\"]\n",
    "runtimes = [UQC_FullEnc_1qubits_runtime, UQC_FullEnc_2qubits_runtime, UQC_FullEnc_2qubits_no_entangle_runtime, \n",
    "            UQC_FullEnc_4qubits_runtime, UQC_FullEnc_4qubits_no_entangle_runtime]\n",
    "\n",
    "# Create a 1x3 grid of subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot mean gradient norms for Full Encoding in the first subplot (top-left)\n",
    "axs[0].plot(UQC_FullEnc_1qubits_norm_grads, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_2qubits_norm_grads, color=\"green\", label=\"Two-Qubit Full UQC\")\n",
    "axs[0].plot(UQC_PartialEnc_2qubits_norm_grads, color=\"blue\", label=\"Two-Qubit Partial UQC\")\n",
    "axs[0].plot(UQC_FullEnc_4qubits_norm_grads, color=\"purple\", label=\"Four-Qubit Full UQC\")\n",
    "axs[0].plot(UQC_PartialEnc_4qubits_norm_grads, color=\"orange\", label=\"Four-Qubit Partial UQC\")\n",
    "axs[0].set_xlabel(\"Training Batch\", fontsize=12)\n",
    "axs[0].set_ylabel(\"Mean Gradient Norm\", fontsize=12)\n",
    "axs[0].legend(fontsize=12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot variance of gradient norms for Full Encoding in the second subplot (top-right)\n",
    "axs[1].plot(UQC_FullEnc_1qubits_variance_grads, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_2qubits_variance_grads, color=\"green\", label=\"Two-Qubit Full UQC\")\n",
    "axs[1].plot(UQC_PartialEnc_2qubits_variance_grads, color=\"blue\", label=\"Two-Qubit Partial UQC\")\n",
    "axs[1].plot(UQC_FullEnc_4qubits_variance_grads, color=\"purple\", label=\"Four-Qubit Full UQC\")\n",
    "axs[1].plot(UQC_PartialEnc_4qubits_variance_grads, color=\"orange\", label=\"Four-Qubit Partial UQC\")\n",
    "axs[1].set_xlabel(\"Training Batch\", fontsize=12)\n",
    "axs[1].set_ylabel(\"Variance of the Gradient Norm\", fontsize=12)\n",
    "axs[1].legend(fontsize=12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Automatically adjust layout for better fit\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/UQC/uqc_gradients_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UQC Beta Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "uqc_beta_paths = [\n",
    "    \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits\",\n",
    "    \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits_beta\",\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "uqc_model_1qubit = Analysis(uqc_beta_paths[0])\n",
    "uqc_model_1qubit_beta = Analysis(uqc_beta_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "uqc_model_1qubit_rewards = uqc_model_1qubit.get_moving_average(window_size=10)\n",
    "uqc_model_1qubit_beta_rewards = uqc_model_1qubit_beta.get_moving_average(window_size=10)\n",
    "# Compute mean and std for rewards\n",
    "uqc_model_1qubit_rewards_mean = np.mean(uqc_model_1qubit_rewards, axis=0)\n",
    "uqc_model_1qubit_beta_rewards_mean = np.mean(uqc_model_1qubit_beta_rewards, axis=0)\n",
    "uqc_model_1qubit_rewards_std = np.std(uqc_model_1qubit_rewards, axis=0)\n",
    "uqc_model_1qubit_beta_rewards_std = np.std(uqc_model_1qubit_beta_rewards, axis=0)\n",
    "\n",
    "uqc_model_1qubit_loss = uqc_model_1qubit.compute_mean_loss()\n",
    "uqc_model_1qubit_beta_loss = uqc_model_1qubit_beta.compute_mean_loss()\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "uqc_model_1qubit_norm_grads, uqc_model_1qubit_variance_grads = uqc_model_1qubit.compute_norm_and_variance()\n",
    "uqc_model_1qubit_beta_norm_grads, uqc_model_1qubit_beta_variance_grads = uqc_model_1qubit_beta.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(uqc_model_1qubit_rewards_mean, color=\"red\", label=\"Four-Qubit UQC\")\n",
    "plt.plot(uqc_model_1qubit_beta_rewards_mean, color=\"blue\", label=\"Four Qubit UQC w/ Beta Scheduling\")\n",
    "plt.fill_between(np.arange(len(uqc_model_1qubit_rewards_mean)), \n",
    "                       np.clip(uqc_model_1qubit_rewards_mean - uqc_model_1qubit_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(uqc_model_1qubit_rewards_mean + uqc_model_1qubit_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "plt.fill_between(np.arange(len(uqc_model_1qubit_beta_rewards_mean)), \n",
    "                       np.clip(uqc_model_1qubit_beta_rewards_mean - uqc_model_1qubit_beta_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(uqc_model_1qubit_beta_rewards_mean + uqc_model_1qubit_beta_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/UQC/uqc_beta_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "uqc_beta_paths = [\n",
    "    \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_4qubits\",\n",
    "    \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_4qubits_beta\",\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "uqc_model_1qubit = Analysis(uqc_beta_paths[0])\n",
    "uqc_model_1qubit_beta = Analysis(uqc_beta_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "uqc_model_1qubit_rewards = uqc_model_1qubit.get_moving_average(window_size=10)\n",
    "uqc_model_1qubit_beta_rewards = uqc_model_1qubit_beta.get_moving_average(window_size=10)\n",
    "# Compute mean and std for rewards\n",
    "uqc_model_1qubit_rewards_mean = np.mean(uqc_model_1qubit_rewards, axis=0)\n",
    "uqc_model_1qubit_beta_rewards_mean = np.mean(uqc_model_1qubit_beta_rewards, axis=0)\n",
    "uqc_model_1qubit_rewards_std = np.std(uqc_model_1qubit_rewards, axis=0)\n",
    "uqc_model_1qubit_beta_rewards_std = np.std(uqc_model_1qubit_beta_rewards, axis=0)\n",
    "\n",
    "uqc_model_1qubit_loss = uqc_model_1qubit.compute_mean_loss()\n",
    "uqc_model_1qubit_beta_loss = uqc_model_1qubit_beta.compute_mean_loss()\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "uqc_model_1qubit_norm_grads, uqc_model_1qubit_variance_grads = uqc_model_1qubit.compute_norm_and_variance()\n",
    "uqc_model_1qubit_beta_norm_grads, uqc_model_1qubit_beta_variance_grads = uqc_model_1qubit_beta.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(uqc_model_1qubit_rewards_mean, color=\"red\", label=\"Four-Qubit UQC\")\n",
    "plt.plot(uqc_model_1qubit_beta_rewards_mean, color=\"blue\", label=\"Four Qubit UQC w/ Beta Scheduling\")\n",
    "plt.fill_between(np.arange(len(uqc_model_1qubit_rewards_mean)), \n",
    "                       np.clip(uqc_model_1qubit_rewards_mean - uqc_model_1qubit_rewards_std, a_min=-500, a_max=-75),\n",
    "                       np.clip(uqc_model_1qubit_rewards_mean + uqc_model_1qubit_rewards_std, a_min=-500, a_max=-75),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "plt.fill_between(np.arange(len(uqc_model_1qubit_beta_rewards_mean)), \n",
    "                       np.clip(uqc_model_1qubit_beta_rewards_mean - uqc_model_1qubit_beta_rewards_std, a_min=-500, a_max=-75),\n",
    "                       np.clip(uqc_model_1qubit_beta_rewards_mean + uqc_model_1qubit_beta_rewards_std, a_min=-500, a_max=-75),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.ylim(-500,0)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/UQC/uqc_beta_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UQC Qubit scalling test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "UQC_FullEnc_paths = [ \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_1qubits\",\n",
    "                      \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_2qubits\",\n",
    "                      \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits\",\n",
    "                      \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_6qubits\",\n",
    "                      \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_8qubits\",\n",
    "                      \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_10qubits\"]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "UQC_FullEnc_1qubits = Analysis(UQC_FullEnc_paths[0])\n",
    "UQC_FullEnc_2qubits = Analysis(UQC_FullEnc_paths[1])\n",
    "UQC_FullEnc_4qubits = Analysis(UQC_FullEnc_paths[2])\n",
    "UQC_FullEnc_6qubits = Analysis(UQC_FullEnc_paths[3])\n",
    "UQC_FullEnc_8qubits = Analysis(UQC_FullEnc_paths[4])\n",
    "UQC_FullEnc_10qubits = Analysis(UQC_FullEnc_paths[5])\n",
    "\n",
    "# Compute moving averages for all qubit sizes\n",
    "UQC_FullEnc_1qubits_rewards = UQC_FullEnc_1qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_2qubits_rewards = UQC_FullEnc_2qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_4qubits_rewards = UQC_FullEnc_4qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_6qubits_rewards = UQC_FullEnc_6qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_8qubits_rewards = UQC_FullEnc_8qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_10qubits_rewards = UQC_FullEnc_10qubits.get_moving_average(window_size=10)\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards_mean = np.mean(UQC_FullEnc_1qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_rewards_mean = np.mean(UQC_FullEnc_2qubits_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_rewards_mean = np.mean(UQC_FullEnc_4qubits_rewards, axis=0)\n",
    "UQC_FullEnc_6qubits_rewards_mean = np.mean(UQC_FullEnc_6qubits_rewards, axis=0)\n",
    "UQC_FullEnc_8qubits_rewards_mean = np.mean(UQC_FullEnc_8qubits_rewards, axis=0)\n",
    "UQC_FullEnc_10qubits_rewards_mean = np.mean(UQC_FullEnc_10qubits_rewards, axis=0)\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards_std = np.std(UQC_FullEnc_1qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_rewards_std = np.std(UQC_FullEnc_2qubits_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_rewards_std = np.std(UQC_FullEnc_4qubits_rewards, axis=0)\n",
    "UQC_FullEnc_6qubits_rewards_std = np.std(UQC_FullEnc_6qubits_rewards, axis=0)\n",
    "UQC_FullEnc_8qubits_rewards_std = np.std(UQC_FullEnc_8qubits_rewards, axis=0)\n",
    "UQC_FullEnc_10qubits_rewards_std = np.std(UQC_FullEnc_10qubits_rewards, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate gradients for all qubit sizes\n",
    "UQC_FullEnc_1qubits_norm_grads, UQC_FullEnc_1qubits_variance_grads = UQC_FullEnc_1qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_2qubits_norm_grads, UQC_FullEnc_2qubits_variance_grads = UQC_FullEnc_2qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_4qubits_norm_grads, UQC_FullEnc_4qubits_variance_grads = UQC_FullEnc_4qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_6qubits_norm_grads, UQC_FullEnc_6qubits_variance_grads = UQC_FullEnc_6qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_8qubits_norm_grads, UQC_FullEnc_8qubits_variance_grads = UQC_FullEnc_8qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_10qubits_norm_grads, UQC_FullEnc_10qubits_variance_grads = UQC_FullEnc_10qubits.compute_norm_and_variance()\n",
    "\n",
    "# Calculate runtimes for all qubit sizes\n",
    "UQC_FullEnc_1qubits_runtime = sum(map(sum, UQC_FullEnc_1qubits.get_runtime())) / len(UQC_FullEnc_1qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_2qubits_runtime = sum(map(sum, UQC_FullEnc_2qubits.get_runtime())) / len(UQC_FullEnc_2qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_4qubits_runtime = sum(map(sum, UQC_FullEnc_4qubits.get_runtime())) / len(UQC_FullEnc_4qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_6qubits_runtime = sum(map(sum, UQC_FullEnc_6qubits.get_runtime())) / len(UQC_FullEnc_6qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_8qubits_runtime = sum(map(sum, UQC_FullEnc_8qubits.get_runtime())) / len(UQC_FullEnc_8qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_10qubits_runtime = sum(map(sum, UQC_FullEnc_10qubits.get_runtime())) / len(UQC_FullEnc_10qubits.get_runtime()) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x3 subplot layout\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5), tight_layout=True)\n",
    "\n",
    "# First plot: Rewards mean with fill between for each configuration\n",
    "axs[0].plot(UQC_FullEnc_1qubits_rewards_mean, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_2qubits_rewards_mean, color=\"blue\", label=\"Two-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_4qubits_rewards_mean, color=\"green\", label=\"Four-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_6qubits_rewards_mean, color=\"purple\", label=\"Six-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_8qubits_rewards_mean, color=\"orange\", label=\"Eight-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_10qubits_rewards_mean, color=\"black\", label=\"Ten-Qubit UQC\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_1qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_1qubits_rewards_mean - UQC_FullEnc_1qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_1qubits_rewards_mean + UQC_FullEnc_1qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_2qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_2qubits_rewards_mean - UQC_FullEnc_2qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_2qubits_rewards_mean + UQC_FullEnc_2qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_4qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_4qubits_rewards_mean - UQC_FullEnc_4qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_4qubits_rewards_mean + UQC_FullEnc_4qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_6qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_6qubits_rewards_mean - UQC_FullEnc_6qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_6qubits_rewards_mean + UQC_FullEnc_6qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"purple\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_8qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_8qubits_rewards_mean - UQC_FullEnc_8qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_8qubits_rewards_mean + UQC_FullEnc_8qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"orange\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_10qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_10qubits_rewards_mean - UQC_FullEnc_10qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(UQC_FullEnc_10qubits_rewards_mean + UQC_FullEnc_10qubits_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"black\")\n",
    "axs[0].set_xlabel(\"Episode\", fontsize=12)\n",
    "axs[0].set_ylabel(\"Mean Return\", fontsize=12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].legend(fontsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second plot: Mean gradient norm for each configuration\n",
    "axs[1].plot(UQC_FullEnc_1qubits_norm_grads, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_2qubits_norm_grads, color=\"blue\", label=\"Two-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_4qubits_norm_grads, color=\"green\", label=\"Four-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_6qubits_norm_grads, color=\"purple\", label=\"Six-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_8qubits_norm_grads, color=\"orange\", label=\"Eight-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_10qubits_norm_grads, color=\"black\", label=\"Ten-Qubit UQC\")\n",
    "axs[1].set_xlabel(\"Training Batch\", fontsize=12)\n",
    "axs[1].set_ylabel(\"Mean Gradient Norm\", fontsize=12)\n",
    "axs[1].legend(fontsize=12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Third plot: Variance of gradient norm for each configuration\n",
    "axs[2].plot(UQC_FullEnc_1qubits_variance_grads, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_2qubits_variance_grads, color=\"blue\", label=\"Two-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_4qubits_variance_grads, color=\"green\", label=\"Four-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_6qubits_variance_grads, color=\"purple\", label=\"Six-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_8qubits_variance_grads, color=\"orange\", label=\"Eight-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_10qubits_variance_grads, color=\"black\", label=\"Ten-Qubit UQC\")\n",
    "axs[2].set_xlabel(\"Training Batch\", fontsize=12)\n",
    "axs[2].set_ylabel(\"Variance of the Gradient Norm\", fontsize=12)\n",
    "axs[2].legend(fontsize=12)\n",
    "axs[2].xaxis.set_tick_params(labelsize=12)\n",
    "axs[2].yaxis.set_tick_params(labelsize=12)\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Save the combined plot as a PDF\n",
    "plt.savefig(\"../../../../data/CartPole-v1/UQC/uqc_qubits_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "UQC_FullEnc_paths = [ \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_1qubits\",\n",
    "                      \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_2qubits\",\n",
    "                      \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_4qubits\",\n",
    "                      \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_6qubits\",\n",
    "                      \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_8qubits\",\n",
    "                      \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_10qubits\"]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "UQC_FullEnc_1qubits = Analysis(UQC_FullEnc_paths[0])\n",
    "UQC_FullEnc_2qubits = Analysis(UQC_FullEnc_paths[1])\n",
    "UQC_FullEnc_4qubits = Analysis(UQC_FullEnc_paths[2])\n",
    "UQC_FullEnc_6qubits = Analysis(UQC_FullEnc_paths[3])\n",
    "UQC_FullEnc_8qubits = Analysis(UQC_FullEnc_paths[4])\n",
    "UQC_FullEnc_10qubits = Analysis(UQC_FullEnc_paths[5])\n",
    "\n",
    "# Compute moving averages for all qubit sizes\n",
    "UQC_FullEnc_1qubits_rewards = UQC_FullEnc_1qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_2qubits_rewards = UQC_FullEnc_2qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_4qubits_rewards = UQC_FullEnc_4qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_6qubits_rewards = UQC_FullEnc_6qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_8qubits_rewards = UQC_FullEnc_8qubits.get_moving_average(window_size=10)\n",
    "UQC_FullEnc_10qubits_rewards = UQC_FullEnc_10qubits.get_moving_average(window_size=10)\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards_mean = np.mean(UQC_FullEnc_1qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_rewards_mean = np.mean(UQC_FullEnc_2qubits_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_rewards_mean = np.mean(UQC_FullEnc_4qubits_rewards, axis=0)\n",
    "UQC_FullEnc_6qubits_rewards_mean = np.mean(UQC_FullEnc_6qubits_rewards, axis=0)\n",
    "UQC_FullEnc_8qubits_rewards_mean = np.mean(UQC_FullEnc_8qubits_rewards, axis=0)\n",
    "UQC_FullEnc_10qubits_rewards_mean = np.mean(UQC_FullEnc_10qubits_rewards, axis=0)\n",
    "\n",
    "UQC_FullEnc_1qubits_rewards_std = np.std(UQC_FullEnc_1qubits_rewards, axis=0)\n",
    "UQC_FullEnc_2qubits_rewards_std = np.std(UQC_FullEnc_2qubits_rewards, axis=0)\n",
    "UQC_FullEnc_4qubits_rewards_std = np.std(UQC_FullEnc_4qubits_rewards, axis=0)\n",
    "UQC_FullEnc_6qubits_rewards_std = np.std(UQC_FullEnc_6qubits_rewards, axis=0)\n",
    "UQC_FullEnc_8qubits_rewards_std = np.std(UQC_FullEnc_8qubits_rewards, axis=0)\n",
    "UQC_FullEnc_10qubits_rewards_std = np.std(UQC_FullEnc_10qubits_rewards, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate gradients for all qubit sizes\n",
    "UQC_FullEnc_1qubits_norm_grads, UQC_FullEnc_1qubits_variance_grads = UQC_FullEnc_1qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_2qubits_norm_grads, UQC_FullEnc_2qubits_variance_grads = UQC_FullEnc_2qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_4qubits_norm_grads, UQC_FullEnc_4qubits_variance_grads = UQC_FullEnc_4qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_6qubits_norm_grads, UQC_FullEnc_6qubits_variance_grads = UQC_FullEnc_6qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_8qubits_norm_grads, UQC_FullEnc_8qubits_variance_grads = UQC_FullEnc_8qubits.compute_norm_and_variance()\n",
    "UQC_FullEnc_10qubits_norm_grads, UQC_FullEnc_10qubits_variance_grads = UQC_FullEnc_10qubits.compute_norm_and_variance()\n",
    "\n",
    "# Calculate runtimes for all qubit sizes\n",
    "UQC_FullEnc_1qubits_runtime = sum(map(sum, UQC_FullEnc_1qubits.get_runtime())) / len(UQC_FullEnc_1qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_2qubits_runtime = sum(map(sum, UQC_FullEnc_2qubits.get_runtime())) / len(UQC_FullEnc_2qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_4qubits_runtime = sum(map(sum, UQC_FullEnc_4qubits.get_runtime())) / len(UQC_FullEnc_4qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_6qubits_runtime = sum(map(sum, UQC_FullEnc_6qubits.get_runtime())) / len(UQC_FullEnc_6qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_8qubits_runtime = sum(map(sum, UQC_FullEnc_8qubits.get_runtime())) / len(UQC_FullEnc_8qubits.get_runtime()) / 60\n",
    "UQC_FullEnc_10qubits_runtime = sum(map(sum, UQC_FullEnc_10qubits.get_runtime())) / len(UQC_FullEnc_10qubits.get_runtime()) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x3 subplot layout\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5), tight_layout=True)\n",
    "\n",
    "# First plot: Rewards mean with fill between for each configuration\n",
    "axs[0].plot(UQC_FullEnc_1qubits_rewards_mean, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_2qubits_rewards_mean, color=\"blue\", label=\"Two-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_4qubits_rewards_mean, color=\"green\", label=\"Four-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_6qubits_rewards_mean, color=\"purple\", label=\"Six-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_8qubits_rewards_mean, color=\"orange\", label=\"Eight-Qubit UQC\")\n",
    "axs[0].plot(UQC_FullEnc_10qubits_rewards_mean, color=\"black\", label=\"Ten-Qubit UQC\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_1qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_1qubits_rewards_mean - UQC_FullEnc_1qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_1qubits_rewards_mean + UQC_FullEnc_1qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_2qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_2qubits_rewards_mean - UQC_FullEnc_2qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_2qubits_rewards_mean + UQC_FullEnc_2qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_4qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_4qubits_rewards_mean - UQC_FullEnc_4qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_4qubits_rewards_mean + UQC_FullEnc_4qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_6qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_6qubits_rewards_mean - UQC_FullEnc_6qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_6qubits_rewards_mean + UQC_FullEnc_6qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"purple\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_8qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_8qubits_rewards_mean - UQC_FullEnc_8qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_8qubits_rewards_mean + UQC_FullEnc_8qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"orange\")\n",
    "axs[0].fill_between(np.arange(len(UQC_FullEnc_10qubits_rewards_mean)), \n",
    "                    np.clip(UQC_FullEnc_10qubits_rewards_mean - UQC_FullEnc_10qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(UQC_FullEnc_10qubits_rewards_mean + UQC_FullEnc_10qubits_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"black\")\n",
    "axs[0].set_xlabel(\"Episode\", fontsize=12)\n",
    "axs[0].set_ylabel(\"Mean Return\", fontsize=12)\n",
    "axs[0].set_ylim(-500,0)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].legend(fontsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second plot: Mean gradient norm for each configuration\n",
    "axs[1].plot(UQC_FullEnc_1qubits_norm_grads, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_2qubits_norm_grads, color=\"blue\", label=\"Two-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_4qubits_norm_grads, color=\"green\", label=\"Four-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_6qubits_norm_grads, color=\"purple\", label=\"Six-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_8qubits_norm_grads, color=\"orange\", label=\"Eight-Qubit UQC\")\n",
    "axs[1].plot(UQC_FullEnc_10qubits_norm_grads, color=\"black\", label=\"Ten-Qubit UQC\")\n",
    "axs[1].set_xlabel(\"Training Batch\", fontsize=12)\n",
    "axs[1].set_ylabel(\"Mean Gradient Norm\", fontsize=12)\n",
    "axs[1].legend(fontsize=12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Third plot: Variance of gradient norm for each configuration\n",
    "axs[2].plot(UQC_FullEnc_1qubits_variance_grads, color=\"red\", label=\"Single-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_2qubits_variance_grads, color=\"blue\", label=\"Two-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_4qubits_variance_grads, color=\"green\", label=\"Four-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_6qubits_variance_grads, color=\"purple\", label=\"Six-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_8qubits_variance_grads, color=\"orange\", label=\"Eight-Qubit UQC\")\n",
    "axs[2].plot(UQC_FullEnc_10qubits_variance_grads, color=\"black\", label=\"Ten-Qubit UQC\")\n",
    "axs[2].set_xlabel(\"Training Batch\", fontsize=12)\n",
    "axs[2].set_ylabel(\"Variance of the Gradient Norm\", fontsize=12)\n",
    "axs[2].legend(fontsize=12)\n",
    "axs[2].xaxis.set_tick_params(labelsize=12)\n",
    "axs[2].yaxis.set_tick_params(labelsize=12)\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Save the combined plot as a PDF\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/UQC/uqc_qubits_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jerbi Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jerbi Raw vs Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_policies_paths = [\n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer_raw_contiguous\",\n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer_raw_parity\",\n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "jerbi_model_raw_contiguous = Analysis(jerbi_policies_paths[0])\n",
    "jerbi_model_raw_parity = Analysis(jerbi_policies_paths[1])\n",
    "jerbi_model_softmax = Analysis(jerbi_policies_paths[2])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_model_raw_contiguous_rewards = jerbi_model_raw_contiguous.get_moving_average(window_size=10)\n",
    "jerbi_model_raw_parity_rewards = jerbi_model_raw_parity.get_moving_average(window_size=10)\n",
    "jerbi_model_softmax_rewards = jerbi_model_softmax.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_model_raw_contiguous_rewards_mean = np.mean(jerbi_model_raw_contiguous_rewards, axis=0)\n",
    "jerbi_model_raw_parity_rewards_mean = np.mean(jerbi_model_raw_parity_rewards, axis=0)\n",
    "jerbi_model_softmax_rewards_mean = np.mean(jerbi_model_softmax_rewards, axis=0)\n",
    "\n",
    "jerbi_model_raw_contiguous_rewards_std = np.std(jerbi_model_raw_contiguous_rewards, axis=0)\n",
    "jerbi_model_raw_parity_rewards_std = np.std(jerbi_model_raw_parity_rewards, axis=0)\n",
    "jerbi_model_softmax_rewards_std = np.std(jerbi_model_softmax_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_model_raw_contiguous_norm_grads, jerbi_model_raw_contiguous_variance_grads = jerbi_model_raw_contiguous.compute_norm_and_variance()\n",
    "jerbi_model_raw_parity_norm_grads, jerbi_model_raw_parity_variance_grads = jerbi_model_raw_parity.compute_norm_and_variance()\n",
    "jerbi_model_softmax_norm_grads, jerbi_model_softmax_variance_grads = jerbi_model_softmax.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "plt.plot(jerbi_model_raw_contiguous_rewards_mean, color=\"red\", label=\"Raw Contiguous\")\n",
    "plt.plot(jerbi_model_raw_parity_rewards_mean, color=\"green\", label=\"Raw Parity\")\n",
    "plt.plot(jerbi_model_softmax_rewards_mean, color=\"blue\", label=\"Softmax\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_raw_contiguous_rewards_mean)), \n",
    "                    np.clip(jerbi_model_raw_contiguous_rewards_mean - jerbi_model_raw_contiguous_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(jerbi_model_raw_contiguous_rewards_mean + jerbi_model_raw_contiguous_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_raw_parity_rewards_mean)), \n",
    "                    np.clip(jerbi_model_raw_parity_rewards_mean - jerbi_model_raw_parity_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(jerbi_model_raw_parity_rewards_mean + jerbi_model_raw_parity_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_softmax_rewards_mean)), \n",
    "                    np.clip(jerbi_model_softmax_rewards_mean - jerbi_model_softmax_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(jerbi_model_softmax_rewards_mean + jerbi_model_softmax_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/JERBI/jerbi_policies_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_policies_paths = [\n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer_raw_contiguous\",\n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "jerbi_model_raw_contiguous = Analysis(jerbi_policies_paths[0])\n",
    "jerbi_model_softmax = Analysis(jerbi_policies_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_model_raw_contiguous_rewards = jerbi_model_raw_contiguous.get_moving_average(window_size=10)\n",
    "jerbi_model_softmax_rewards = jerbi_model_softmax.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_model_raw_contiguous_rewards_mean = np.mean(jerbi_model_raw_contiguous_rewards, axis=0)\n",
    "jerbi_model_softmax_rewards_mean = np.mean(jerbi_model_softmax_rewards, axis=0)\n",
    "\n",
    "jerbi_model_raw_contiguous_rewards_std = np.std(jerbi_model_raw_contiguous_rewards, axis=0)\n",
    "jerbi_model_softmax_rewards_std = np.std(jerbi_model_softmax_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_model_raw_contiguous_norm_grads, jerbi_model_raw_contiguous_variance_grads = jerbi_model_raw_contiguous.compute_norm_and_variance()\n",
    "jerbi_model_softmax_norm_grads, jerbi_model_softmax_variance_grads = jerbi_model_softmax.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "plt.plot(jerbi_model_raw_contiguous_rewards_mean, color=\"red\", label=\"Raw Contiguous\")\n",
    "plt.plot(jerbi_model_softmax_rewards_mean, color=\"green\", label=\"Softmax\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_raw_contiguous_rewards_mean)), \n",
    "                    np.clip(jerbi_model_raw_contiguous_rewards_mean - jerbi_model_raw_contiguous_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(jerbi_model_raw_contiguous_rewards_mean + jerbi_model_raw_contiguous_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_softmax_rewards_mean)), \n",
    "                    np.clip(jerbi_model_softmax_rewards_mean - jerbi_model_softmax_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(jerbi_model_softmax_rewards_mean + jerbi_model_softmax_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/JERBI/jerbi_policies_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jerbi Baseline vs Data reup (output and input scalling tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_baseline_paths = [\n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_1layer\", \n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_1layer_input\", \n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_1layer_output\", \n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_1layer_input_output\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects for the updated paths\n",
    "jerbi_baseline_layer = Analysis(jerbi_baseline_paths[0])\n",
    "jerbi_baseline_input = Analysis(jerbi_baseline_paths[1])\n",
    "jerbi_baseline_output = Analysis(jerbi_baseline_paths[2])\n",
    "jerbi_baseline_input_output = Analysis(jerbi_baseline_paths[3])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_baseline_layer_rewards = jerbi_baseline_layer.get_moving_average(window_size=10)\n",
    "jerbi_baseline_input_rewards = jerbi_baseline_input.get_moving_average(window_size=10)\n",
    "jerbi_baseline_output_rewards = jerbi_baseline_output.get_moving_average(window_size=10)\n",
    "jerbi_baseline_input_output_rewards = jerbi_baseline_input_output.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_baseline_layer_rewards_mean = np.mean(jerbi_baseline_layer_rewards, axis=0)\n",
    "jerbi_baseline_input_rewards_mean = np.mean(jerbi_baseline_input_rewards, axis=0)\n",
    "jerbi_baseline_output_rewards_mean = np.mean(jerbi_baseline_output_rewards, axis=0)\n",
    "jerbi_baseline_input_output_rewards_mean = np.mean(jerbi_baseline_input_output_rewards, axis=0)\n",
    "\n",
    "jerbi_baseline_layer_rewards_std = np.std(jerbi_baseline_layer_rewards, axis=0)\n",
    "jerbi_baseline_input_rewards_std = np.std(jerbi_baseline_input_rewards, axis=0)\n",
    "jerbi_baseline_output_rewards_std = np.std(jerbi_baseline_output_rewards, axis=0)\n",
    "jerbi_baseline_input_output_rewards_std = np.std(jerbi_baseline_input_output_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_baseline_layer_norm_grads, jerbi_baseline_layer_variance_grads = jerbi_baseline_layer.compute_norm_and_variance()\n",
    "jerbi_baseline_input_norm_grads, jerbi_baseline_input_variance_grads = jerbi_baseline_input.compute_norm_and_variance()\n",
    "jerbi_baseline_output_norm_grads, jerbi_baseline_output_variance_grads = jerbi_baseline_output.compute_norm_and_variance()\n",
    "jerbi_baseline_input_output_norm_grads, jerbi_baseline_input_output_variance_grads = jerbi_baseline_input_output.compute_norm_and_variance()\n",
    "\n",
    "\n",
    "\n",
    "jerbi_datareup_paths = [\n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer\", \n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer_input\", \n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer_output\", \n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer_input_output\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects for the updated paths\n",
    "jerbi_datareup_layer = Analysis(jerbi_datareup_paths[0])\n",
    "jerbi_datareup_input = Analysis(jerbi_datareup_paths[1])\n",
    "jerbi_datareup_output = Analysis(jerbi_datareup_paths[2])\n",
    "jerbi_datareup_input_output = Analysis(jerbi_datareup_paths[3])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_datareup_layer_rewards = jerbi_datareup_layer.get_moving_average(window_size=10)\n",
    "jerbi_datareup_input_rewards = jerbi_datareup_input.get_moving_average(window_size=10)\n",
    "jerbi_datareup_output_rewards = jerbi_datareup_output.get_moving_average(window_size=10)\n",
    "jerbi_datareup_input_output_rewards = jerbi_datareup_input_output.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_datareup_layer_rewards_mean = np.mean(jerbi_datareup_layer_rewards, axis=0)\n",
    "jerbi_datareup_input_rewards_mean = np.mean(jerbi_datareup_input_rewards, axis=0)\n",
    "jerbi_datareup_output_rewards_mean = np.mean(jerbi_datareup_output_rewards, axis=0)\n",
    "jerbi_datareup_input_output_rewards_mean = np.mean(jerbi_datareup_input_output_rewards, axis=0)\n",
    "\n",
    "jerbi_datareup_layer_rewards_std = np.std(jerbi_datareup_layer_rewards, axis=0)\n",
    "jerbi_datareup_input_rewards_std = np.std(jerbi_datareup_input_rewards, axis=0)\n",
    "jerbi_datareup_output_rewards_std = np.std(jerbi_datareup_output_rewards, axis=0)\n",
    "jerbi_datareup_input_output_rewards_std = np.std(jerbi_datareup_input_output_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_datareup_layer_norm_grads, jerbi_datareup_layer_variance_grads = jerbi_datareup_layer.compute_norm_and_variance()\n",
    "jerbi_datareup_input_norm_grads, jerbi_datareup_input_variance_grads = jerbi_datareup_input.compute_norm_and_variance()\n",
    "jerbi_datareup_output_norm_grads, jerbi_datareup_output_variance_grads = jerbi_datareup_output.compute_norm_and_variance()\n",
    "jerbi_datareup_input_output_norm_grads, jerbi_datareup_input_output_variance_grads = jerbi_datareup_input_output.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "# First Plot: Baseline\n",
    "# Plot rewards mean for jerbi_baseline\n",
    "axs[0].plot(jerbi_baseline_layer_rewards_mean, color=\"red\", label=\"Single-Layer\")\n",
    "axs[0].plot(jerbi_baseline_input_rewards_mean, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[0].plot(jerbi_baseline_output_rewards_mean, color=\"green\", label=\"Single-Layer w/o Output Scaling\")\n",
    "axs[0].plot(jerbi_baseline_input_output_rewards_mean, color=\"purple\", label=\"Single-Layer w/o Input & Output Scaling\")\n",
    "\n",
    "# Fill between for standard deviation for jerbi_baseline\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_layer_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_layer_rewards_mean - jerbi_baseline_layer_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_baseline_layer_rewards_mean + jerbi_baseline_layer_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_input_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_input_rewards_mean - jerbi_baseline_input_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_baseline_input_rewards_mean + jerbi_baseline_input_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_output_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_output_rewards_mean - jerbi_baseline_output_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_baseline_output_rewards_mean + jerbi_baseline_output_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"green\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_input_output_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_input_output_rewards_mean - jerbi_baseline_input_output_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_baseline_input_output_rewards_mean + jerbi_baseline_input_output_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"purple\")\n",
    "\n",
    "axs[0].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[0].legend(fontsize = 12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second Plot: Datareup\n",
    "# Plot rewards mean for jerbi_datareup\n",
    "axs[1].plot(jerbi_datareup_layer_rewards_mean, color=\"red\", label=\"Multi-Layer\")\n",
    "axs[1].plot(jerbi_datareup_input_rewards_mean, color=\"blue\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[1].plot(jerbi_datareup_output_rewards_mean, color=\"green\", label=\"Multi-Layer w/o Output Scaling\")\n",
    "axs[1].plot(jerbi_datareup_input_output_rewards_mean, color=\"purple\", label=\"Multi-Layer w/o Input & Output Scaling\")\n",
    "\n",
    "# Fill between for standard deviation for jerbi_datareup\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_layer_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_layer_rewards_mean - jerbi_datareup_layer_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_datareup_layer_rewards_mean + jerbi_datareup_layer_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_input_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_input_rewards_mean - jerbi_datareup_input_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_datareup_input_rewards_mean + jerbi_datareup_input_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_output_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_output_rewards_mean - jerbi_datareup_output_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_datareup_output_rewards_mean + jerbi_datareup_output_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"green\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_input_output_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_input_output_rewards_mean - jerbi_datareup_input_output_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_datareup_input_output_rewards_mean + jerbi_datareup_input_output_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"purple\")\n",
    "\n",
    "axs[1].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[1].legend(fontsize = 12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/JERBI/jerbi_datareup_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "# Plot mean gradient norm\n",
    "axs[0].plot(jerbi_baseline_layer_norm_grads, color=\"red\", label=\"Single-Layer\")\n",
    "axs[0].plot(jerbi_baseline_input_norm_grads, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[0].plot(jerbi_datareup_layer_norm_grads, color=\"green\", label=\"Multi-Layer\")\n",
    "axs[0].plot(jerbi_datareup_input_norm_grads, color=\"purple\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[0].set_xlabel(\"Training Batch\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Gradient Norm\", fontsize = 12)\n",
    "axs[0].legend(fontsize = 12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot variance of gradient norm\n",
    "axs[1].plot(jerbi_baseline_layer_variance_grads, color=\"red\", label=\"Single-Layer\")\n",
    "axs[1].plot(jerbi_baseline_input_variance_grads, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[1].plot(jerbi_datareup_layer_variance_grads, color=\"green\", label=\"Multi-Layer\")\n",
    "axs[1].plot(jerbi_datareup_input_variance_grads, color=\"purple\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[1].set_xlabel(\"Training Batch\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Variance of the Gradient Norm\", fontsize = 12)\n",
    "axs[1].legend(fontsize = 12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/JERBI/jerbi_gradients_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_baseline_paths = [\n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_1layer\", \n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_1layer_input\", \n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_1layer_output\", \n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_1layer_input_output\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects for the updated paths\n",
    "jerbi_baseline_layer = Analysis(jerbi_baseline_paths[0])\n",
    "jerbi_baseline_input = Analysis(jerbi_baseline_paths[1])\n",
    "jerbi_baseline_output = Analysis(jerbi_baseline_paths[2])\n",
    "jerbi_baseline_input_output = Analysis(jerbi_baseline_paths[3])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_baseline_layer_rewards = jerbi_baseline_layer.get_moving_average(window_size=10)\n",
    "jerbi_baseline_input_rewards = jerbi_baseline_input.get_moving_average(window_size=10)\n",
    "jerbi_baseline_output_rewards = jerbi_baseline_output.get_moving_average(window_size=10)\n",
    "jerbi_baseline_input_output_rewards = jerbi_baseline_input_output.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_baseline_layer_rewards_mean = np.mean(jerbi_baseline_layer_rewards, axis=0)\n",
    "jerbi_baseline_input_rewards_mean = np.mean(jerbi_baseline_input_rewards, axis=0)\n",
    "jerbi_baseline_output_rewards_mean = np.mean(jerbi_baseline_output_rewards, axis=0)\n",
    "jerbi_baseline_input_output_rewards_mean = np.mean(jerbi_baseline_input_output_rewards, axis=0)\n",
    "\n",
    "jerbi_baseline_layer_rewards_std = np.std(jerbi_baseline_layer_rewards, axis=0)\n",
    "jerbi_baseline_input_rewards_std = np.std(jerbi_baseline_input_rewards, axis=0)\n",
    "jerbi_baseline_output_rewards_std = np.std(jerbi_baseline_output_rewards, axis=0)\n",
    "jerbi_baseline_input_output_rewards_std = np.std(jerbi_baseline_input_output_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_baseline_layer_norm_grads, jerbi_baseline_layer_variance_grads = jerbi_baseline_layer.compute_norm_and_variance()\n",
    "jerbi_baseline_input_norm_grads, jerbi_baseline_input_variance_grads = jerbi_baseline_input.compute_norm_and_variance()\n",
    "jerbi_baseline_output_norm_grads, jerbi_baseline_output_variance_grads = jerbi_baseline_output.compute_norm_and_variance()\n",
    "jerbi_baseline_input_output_norm_grads, jerbi_baseline_input_output_variance_grads = jerbi_baseline_input_output.compute_norm_and_variance()\n",
    "\n",
    "\n",
    "\n",
    "jerbi_datareup_paths = [\n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer\", \n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer_input\", \n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer_output\", \n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer_input_output\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects for the updated paths\n",
    "jerbi_datareup_layer = Analysis(jerbi_datareup_paths[0])\n",
    "jerbi_datareup_input = Analysis(jerbi_datareup_paths[1])\n",
    "jerbi_datareup_output = Analysis(jerbi_datareup_paths[2])\n",
    "jerbi_datareup_input_output = Analysis(jerbi_datareup_paths[3])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_datareup_layer_rewards = jerbi_datareup_layer.get_moving_average(window_size=10)\n",
    "jerbi_datareup_input_rewards = jerbi_datareup_input.get_moving_average(window_size=10)\n",
    "jerbi_datareup_output_rewards = jerbi_datareup_output.get_moving_average(window_size=10)\n",
    "jerbi_datareup_input_output_rewards = jerbi_datareup_input_output.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_datareup_layer_rewards_mean = np.mean(jerbi_datareup_layer_rewards, axis=0)\n",
    "jerbi_datareup_input_rewards_mean = np.mean(jerbi_datareup_input_rewards, axis=0)\n",
    "jerbi_datareup_output_rewards_mean = np.mean(jerbi_datareup_output_rewards, axis=0)\n",
    "jerbi_datareup_input_output_rewards_mean = np.mean(jerbi_datareup_input_output_rewards, axis=0)\n",
    "\n",
    "jerbi_datareup_layer_rewards_std = np.std(jerbi_datareup_layer_rewards, axis=0)\n",
    "jerbi_datareup_input_rewards_std = np.std(jerbi_datareup_input_rewards, axis=0)\n",
    "jerbi_datareup_output_rewards_std = np.std(jerbi_datareup_output_rewards, axis=0)\n",
    "jerbi_datareup_input_output_rewards_std = np.std(jerbi_datareup_input_output_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_datareup_layer_norm_grads, jerbi_datareup_layer_variance_grads = jerbi_datareup_layer.compute_norm_and_variance()\n",
    "jerbi_datareup_input_norm_grads, jerbi_datareup_input_variance_grads = jerbi_datareup_input.compute_norm_and_variance()\n",
    "jerbi_datareup_output_norm_grads, jerbi_datareup_output_variance_grads = jerbi_datareup_output.compute_norm_and_variance()\n",
    "jerbi_datareup_input_output_norm_grads, jerbi_datareup_input_output_variance_grads = jerbi_datareup_input_output.compute_norm_and_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "# First Plot: Baseline\n",
    "# Plot rewards mean for jerbi_baseline\n",
    "axs[0].plot(jerbi_baseline_layer_rewards_mean, color=\"red\", label=\"Single-Layer\")\n",
    "axs[0].plot(jerbi_baseline_input_rewards_mean, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[0].plot(jerbi_baseline_output_rewards_mean, color=\"green\", label=\"Single-Layer w/o Output Scaling\")\n",
    "axs[0].plot(jerbi_baseline_input_output_rewards_mean, color=\"purple\", label=\"Single-Layer w/o Input & Output Scaling\")\n",
    "\n",
    "# Fill between for standard deviation for jerbi_baseline\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_layer_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_layer_rewards_mean - jerbi_baseline_layer_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_baseline_layer_rewards_mean + jerbi_baseline_layer_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_input_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_input_rewards_mean - jerbi_baseline_input_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_baseline_input_rewards_mean + jerbi_baseline_input_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_output_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_output_rewards_mean - jerbi_baseline_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_baseline_output_rewards_mean + jerbi_baseline_output_rewards_std, a_min=-500, a_max=-75),\n",
    "                       alpha=0.2, color=\"green\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_input_output_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_input_output_rewards_mean - jerbi_baseline_input_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_baseline_input_output_rewards_mean + jerbi_baseline_input_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"purple\")\n",
    "\n",
    "axs[0].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[0].legend(fontsize = 12, loc='upper left')\n",
    "axs[0].set_ylim(-500,0)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second Plot: Datareup\n",
    "# Plot rewards mean for jerbi_datareup\n",
    "axs[1].plot(jerbi_datareup_layer_rewards_mean, color=\"red\", label=\"Multi-Layer\")\n",
    "axs[1].plot(jerbi_datareup_input_rewards_mean, color=\"blue\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[1].plot(jerbi_datareup_output_rewards_mean, color=\"green\", label=\"Multi-Layer w/o Output Scaling\")\n",
    "axs[1].plot(jerbi_datareup_input_output_rewards_mean, color=\"purple\", label=\"Multi-Layer w/o Input & Output Scaling\")\n",
    "\n",
    "# Fill between for standard deviation for jerbi_datareup\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_layer_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_layer_rewards_mean - jerbi_datareup_layer_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_datareup_layer_rewards_mean + jerbi_datareup_layer_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_input_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_input_rewards_mean - jerbi_datareup_input_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_datareup_input_rewards_mean + jerbi_datareup_input_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_output_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_output_rewards_mean - jerbi_datareup_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_datareup_output_rewards_mean + jerbi_datareup_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"green\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_input_output_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_input_output_rewards_mean - jerbi_datareup_input_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_datareup_input_output_rewards_mean + jerbi_datareup_input_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"purple\")\n",
    "\n",
    "axs[1].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[1].legend(fontsize = 12, loc='upper left')\n",
    "axs[0].set_ylim(-500,0)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/JERBI/jerbi_datareup_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "# Plot mean gradient norm\n",
    "axs[0].plot(jerbi_baseline_layer_norm_grads, color=\"red\", label=\"Single-Layer\")\n",
    "axs[0].plot(jerbi_baseline_input_norm_grads, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[0].plot(jerbi_datareup_layer_norm_grads, color=\"green\", label=\"Multi-Layer\")\n",
    "axs[0].plot(jerbi_datareup_input_norm_grads, color=\"purple\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[0].set_xlabel(\"Training Batch\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Gradient Norm\", fontsize = 12)\n",
    "axs[0].legend(fontsize = 12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot variance of gradient norm\n",
    "axs[1].plot(jerbi_baseline_layer_variance_grads, color=\"red\", label=\"Single-Layer\")\n",
    "axs[1].plot(jerbi_baseline_input_variance_grads, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[1].plot(jerbi_datareup_layer_variance_grads, color=\"green\", label=\"Multi-Layer\")\n",
    "axs[1].plot(jerbi_datareup_input_variance_grads, color=\"purple\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[1].set_xlabel(\"Training Batch\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Variance of the Gradient Norm\", fontsize = 12)\n",
    "axs[1].legend(fontsize = 12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/JERBI/jerbi_gradients_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jerbi beta tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_paths = [\n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer\",\n",
    "    \"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer_beta\",\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "jerbi = Analysis(jerbi_paths[0])\n",
    "jerbi_beta = Analysis(jerbi_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_rewards = jerbi.get_moving_average(window_size=10)\n",
    "jerbi_beta_rewards = jerbi_beta.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_rewards_mean = np.mean(jerbi_rewards, axis=0)\n",
    "jerbi_beta_rewards_mean = np.mean(jerbi_beta_rewards, axis=0)\n",
    "jerbi_rewards_std = np.std(jerbi_rewards, axis=0)\n",
    "jerbi_beta_rewards_std = np.std(jerbi_beta_rewards, axis=0)\n",
    "\n",
    "# Compute mean loss\n",
    "jerbi_loss = jerbi.compute_mean_loss()\n",
    "jerbi_beta_loss = jerbi_beta.compute_mean_loss()\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_norm_grads, jerbi_variance_grads = jerbi.compute_norm_and_variance()\n",
    "jerbi_beta_norm_grads, jerbi_beta_variance_grads = jerbi_beta.compute_norm_and_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot rewards mean\n",
    "plt.plot(jerbi_rewards_mean, color=\"red\", label=\"Multi-Layer\")\n",
    "plt.plot(jerbi_beta_rewards_mean, color=\"blue\", label=\"Multi-Layer w/ Beta Scheduling\")\n",
    "\n",
    "# Fill between for standard deviation\n",
    "plt.fill_between(np.arange(len(jerbi_rewards_mean)), \n",
    "                 np.clip(jerbi_rewards_mean - jerbi_rewards_std, a_min=0, a_max=500),\n",
    "                 np.clip(jerbi_rewards_mean + jerbi_rewards_std, a_min=0, a_max=500),\n",
    "                 alpha=0.2, color=\"red\")\n",
    "\n",
    "plt.fill_between(np.arange(len(jerbi_beta_rewards_mean)), \n",
    "                 np.clip(jerbi_beta_rewards_mean - jerbi_beta_rewards_std, a_min=0, a_max=500),\n",
    "                 np.clip(jerbi_beta_rewards_mean + jerbi_beta_rewards_std, a_min=0, a_max=500),\n",
    "                 alpha=0.2, color=\"blue\")\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)  # Set x-axis tick size\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)  # Set y-axis tick size\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/JERBI/jerbi_beta_cartpole.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_paths = [\n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer\",\n",
    "    \"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer_beta\",\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "jerbi = Analysis(jerbi_paths[0])\n",
    "jerbi_beta = Analysis(jerbi_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_rewards = jerbi.get_moving_average(window_size=10)\n",
    "jerbi_beta_rewards = jerbi_beta.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_rewards_mean = np.mean(jerbi_rewards, axis=0)\n",
    "jerbi_beta_rewards_mean = np.mean(jerbi_beta_rewards, axis=0)\n",
    "jerbi_rewards_std = np.std(jerbi_rewards, axis=0)\n",
    "jerbi_beta_rewards_std = np.std(jerbi_beta_rewards, axis=0)\n",
    "\n",
    "# Compute mean loss\n",
    "jerbi_loss = jerbi.compute_mean_loss()\n",
    "jerbi_beta_loss = jerbi_beta.compute_mean_loss()\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_norm_grads, jerbi_variance_grads = jerbi.compute_norm_and_variance()\n",
    "jerbi_beta_norm_grads, jerbi_beta_variance_grads = jerbi_beta.compute_norm_and_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot rewards mean\n",
    "plt.plot(jerbi_rewards_mean, color=\"red\", label=\"Multi-Layer\")\n",
    "plt.plot(jerbi_beta_rewards_mean, color=\"blue\", label=\"Multi-Layer w/ Beta Scheduling\")\n",
    "\n",
    "# Fill between for standard deviation\n",
    "plt.fill_between(np.arange(len(jerbi_rewards_mean)), \n",
    "                 np.clip(jerbi_rewards_mean - jerbi_rewards_std, a_min=-500, a_max=0),\n",
    "                 np.clip(jerbi_rewards_mean + jerbi_rewards_std, a_min=-500, a_max=0),\n",
    "                 alpha=0.2, color=\"red\")\n",
    "\n",
    "plt.fill_between(np.arange(len(jerbi_beta_rewards_mean)), \n",
    "                 np.clip(jerbi_beta_rewards_mean - jerbi_beta_rewards_std, a_min=-500, a_max=0),\n",
    "                 np.clip(jerbi_beta_rewards_mean + jerbi_beta_rewards_std, a_min=-500, a_max=0),\n",
    "                 alpha=0.2, color=\"blue\")\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.ylim(-500,0)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/JERBI/jerbi_beta_acrobot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFQ Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFQ Raw vs Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_policies_paths = [\n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer_raw_contiguous\",\n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer_raw_parity\",\n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "jerbi_model_raw_contiguous = Analysis(jerbi_policies_paths[0])\n",
    "jerbi_model_raw_parity = Analysis(jerbi_policies_paths[1])\n",
    "jerbi_model_softmax = Analysis(jerbi_policies_paths[2])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_model_raw_contiguous_rewards = jerbi_model_raw_contiguous.get_moving_average(window_size=10)\n",
    "jerbi_model_raw_parity_rewards = jerbi_model_raw_parity.get_moving_average(window_size=10)\n",
    "jerbi_model_softmax_rewards = jerbi_model_softmax.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_model_raw_contiguous_rewards_mean = np.mean(jerbi_model_raw_contiguous_rewards, axis=0)\n",
    "jerbi_model_raw_parity_rewards_mean = np.mean(jerbi_model_raw_parity_rewards, axis=0)\n",
    "jerbi_model_softmax_rewards_mean = np.mean(jerbi_model_softmax_rewards, axis=0)\n",
    "\n",
    "jerbi_model_raw_contiguous_rewards_std = np.std(jerbi_model_raw_contiguous_rewards, axis=0)\n",
    "jerbi_model_raw_parity_rewards_std = np.std(jerbi_model_raw_parity_rewards, axis=0)\n",
    "jerbi_model_softmax_rewards_std = np.std(jerbi_model_softmax_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_model_raw_contiguous_norm_grads, jerbi_model_raw_contiguous_variance_grads = jerbi_model_raw_contiguous.compute_norm_and_variance()\n",
    "jerbi_model_raw_parity_norm_grads, jerbi_model_raw_parity_variance_grads = jerbi_model_raw_parity.compute_norm_and_variance()\n",
    "jerbi_model_softmax_norm_grads, jerbi_model_softmax_variance_grads = jerbi_model_softmax.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "plt.plot(jerbi_model_raw_contiguous_rewards_mean, color=\"red\", label=\"Raw Contiguous\")\n",
    "plt.plot(jerbi_model_raw_parity_rewards_mean, color=\"blue\", label=\"Raw Parity\")\n",
    "plt.plot(jerbi_model_softmax_rewards_mean, color=\"green\", label=\"Softmax\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_raw_contiguous_rewards_mean)), \n",
    "                    np.clip(jerbi_model_raw_contiguous_rewards_mean - jerbi_model_raw_contiguous_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(jerbi_model_raw_contiguous_rewards_mean + jerbi_model_raw_contiguous_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_raw_parity_rewards_mean)), \n",
    "                    np.clip(jerbi_model_raw_parity_rewards_mean - jerbi_model_raw_parity_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(jerbi_model_raw_parity_rewards_mean + jerbi_model_raw_parity_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"blue\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_softmax_rewards_mean)), \n",
    "                    np.clip(jerbi_model_softmax_rewards_mean - jerbi_model_softmax_rewards_std, a_min=0, a_max=500),\n",
    "                    np.clip(jerbi_model_softmax_rewards_mean + jerbi_model_softmax_rewards_std, a_min=0, a_max=500),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/TFQ/tfq_policies_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_policies_paths = [\n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer_raw_contiguous\",\n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "jerbi_model_raw_contiguous = Analysis(jerbi_policies_paths[0])\n",
    "jerbi_model_softmax = Analysis(jerbi_policies_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_model_raw_contiguous_rewards = jerbi_model_raw_contiguous.get_moving_average(window_size=10)\n",
    "jerbi_model_softmax_rewards = jerbi_model_softmax.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_model_raw_contiguous_rewards_mean = np.mean(jerbi_model_raw_contiguous_rewards, axis=0)\n",
    "jerbi_model_softmax_rewards_mean = np.mean(jerbi_model_softmax_rewards, axis=0)\n",
    "\n",
    "jerbi_model_raw_contiguous_rewards_std = np.std(jerbi_model_raw_contiguous_rewards, axis=0)\n",
    "jerbi_model_softmax_rewards_std = np.std(jerbi_model_softmax_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_model_raw_contiguous_norm_grads, jerbi_model_raw_contiguous_variance_grads = jerbi_model_raw_contiguous.compute_norm_and_variance()\n",
    "jerbi_model_softmax_norm_grads, jerbi_model_softmax_variance_grads = jerbi_model_softmax.compute_norm_and_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "plt.plot(jerbi_model_raw_contiguous_rewards_mean, color=\"red\", label=\"Raw Contiguous\")\n",
    "plt.plot(jerbi_model_softmax_rewards_mean, color=\"green\", label=\"Softmax\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_raw_contiguous_rewards_mean)), \n",
    "                    np.clip(jerbi_model_raw_contiguous_rewards_mean - jerbi_model_raw_contiguous_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(jerbi_model_raw_contiguous_rewards_mean + jerbi_model_raw_contiguous_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"red\")\n",
    "plt.fill_between(np.arange(len(jerbi_model_softmax_rewards_mean)), \n",
    "                    np.clip(jerbi_model_softmax_rewards_mean - jerbi_model_softmax_rewards_std, a_min=-500, a_max=0),\n",
    "                    np.clip(jerbi_model_softmax_rewards_mean + jerbi_model_softmax_rewards_std, a_min=-500, a_max=0),\n",
    "                    alpha=0.2, color=\"green\")\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.ylim(-500,0)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/TFQ/tfq_policies_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFQ Baseline vs Data reup (output and input scalling tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_baseline_paths = [\n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_1layer\", \n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_1layer_input\", \n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_1layer_output\", \n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_1layer_input_output\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects for the updated paths\n",
    "jerbi_baseline_layer = Analysis(jerbi_baseline_paths[0])\n",
    "jerbi_baseline_input = Analysis(jerbi_baseline_paths[1])\n",
    "jerbi_baseline_output = Analysis(jerbi_baseline_paths[2])\n",
    "jerbi_baseline_input_output = Analysis(jerbi_baseline_paths[3])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_baseline_layer_rewards = jerbi_baseline_layer.get_moving_average(window_size=10)\n",
    "jerbi_baseline_input_rewards = jerbi_baseline_input.get_moving_average(window_size=10)\n",
    "jerbi_baseline_output_rewards = jerbi_baseline_output.get_moving_average(window_size=10)\n",
    "jerbi_baseline_input_output_rewards = jerbi_baseline_input_output.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_baseline_layer_rewards_mean = np.mean(jerbi_baseline_layer_rewards, axis=0)\n",
    "jerbi_baseline_input_rewards_mean = np.mean(jerbi_baseline_input_rewards, axis=0)\n",
    "jerbi_baseline_output_rewards_mean = np.mean(jerbi_baseline_output_rewards, axis=0)\n",
    "jerbi_baseline_input_output_rewards_mean = np.mean(jerbi_baseline_input_output_rewards, axis=0)\n",
    "\n",
    "jerbi_baseline_layer_rewards_std = np.std(jerbi_baseline_layer_rewards, axis=0)\n",
    "jerbi_baseline_input_rewards_std = np.std(jerbi_baseline_input_rewards, axis=0)\n",
    "jerbi_baseline_output_rewards_std = np.std(jerbi_baseline_output_rewards, axis=0)\n",
    "jerbi_baseline_input_output_rewards_std = np.std(jerbi_baseline_input_output_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_baseline_layer_norm_grads, jerbi_baseline_layer_variance_grads = jerbi_baseline_layer.compute_norm_and_variance()\n",
    "jerbi_baseline_input_norm_grads, jerbi_baseline_input_variance_grads = jerbi_baseline_input.compute_norm_and_variance()\n",
    "jerbi_baseline_output_norm_grads, jerbi_baseline_output_variance_grads = jerbi_baseline_output.compute_norm_and_variance()\n",
    "jerbi_baseline_input_output_norm_grads, jerbi_baseline_input_output_variance_grads = jerbi_baseline_input_output.compute_norm_and_variance()\n",
    "\n",
    "\n",
    "\n",
    "jerbi_datareup_paths = [\n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer\", \n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer_input\", \n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer_output\", \n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer_input_output\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects for the updated paths\n",
    "jerbi_datareup_layer = Analysis(jerbi_datareup_paths[0])\n",
    "jerbi_datareup_input = Analysis(jerbi_datareup_paths[1])\n",
    "jerbi_datareup_output = Analysis(jerbi_datareup_paths[2])\n",
    "jerbi_datareup_input_output = Analysis(jerbi_datareup_paths[3])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_datareup_layer_rewards = jerbi_datareup_layer.get_moving_average(window_size=10)\n",
    "jerbi_datareup_input_rewards = jerbi_datareup_input.get_moving_average(window_size=10)\n",
    "jerbi_datareup_output_rewards = jerbi_datareup_output.get_moving_average(window_size=10)\n",
    "jerbi_datareup_input_output_rewards = jerbi_datareup_input_output.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_datareup_layer_rewards_mean = np.mean(jerbi_datareup_layer_rewards, axis=0)\n",
    "jerbi_datareup_input_rewards_mean = np.mean(jerbi_datareup_input_rewards, axis=0)\n",
    "jerbi_datareup_output_rewards_mean = np.mean(jerbi_datareup_output_rewards, axis=0)\n",
    "jerbi_datareup_input_output_rewards_mean = np.mean(jerbi_datareup_input_output_rewards, axis=0)\n",
    "\n",
    "jerbi_datareup_layer_rewards_std = np.std(jerbi_datareup_layer_rewards, axis=0)\n",
    "jerbi_datareup_input_rewards_std = np.std(jerbi_datareup_input_rewards, axis=0)\n",
    "jerbi_datareup_output_rewards_std = np.std(jerbi_datareup_output_rewards, axis=0)\n",
    "jerbi_datareup_input_output_rewards_std = np.std(jerbi_datareup_input_output_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_datareup_layer_norm_grads, jerbi_datareup_layer_variance_grads = jerbi_datareup_layer.compute_norm_and_variance()\n",
    "jerbi_datareup_input_norm_grads, jerbi_datareup_input_variance_grads = jerbi_datareup_input.compute_norm_and_variance()\n",
    "jerbi_datareup_output_norm_grads, jerbi_datareup_output_variance_grads = jerbi_datareup_output.compute_norm_and_variance()\n",
    "jerbi_datareup_input_output_norm_grads, jerbi_datareup_input_output_variance_grads = jerbi_datareup_input_output.compute_norm_and_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "# First Plot: Baseline\n",
    "# Plot rewards mean for jerbi_baseline\n",
    "axs[0].plot(jerbi_baseline_layer_rewards_mean, color=\"red\", label=\"Single-Layer\")\n",
    "axs[0].plot(jerbi_baseline_input_rewards_mean, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[0].plot(jerbi_baseline_output_rewards_mean, color=\"green\", label=\"Single-Layer w/o Output Scaling\")\n",
    "axs[0].plot(jerbi_baseline_input_output_rewards_mean, color=\"purple\", label=\"Single-Layer w/o Input & Output Scaling\")\n",
    "\n",
    "# Fill between for standard deviation for jerbi_baseline\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_layer_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_layer_rewards_mean - jerbi_baseline_layer_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_baseline_layer_rewards_mean + jerbi_baseline_layer_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_input_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_input_rewards_mean - jerbi_baseline_input_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_baseline_input_rewards_mean + jerbi_baseline_input_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_output_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_output_rewards_mean - jerbi_baseline_output_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_baseline_output_rewards_mean + jerbi_baseline_output_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"green\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_input_output_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_input_output_rewards_mean - jerbi_baseline_input_output_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_baseline_input_output_rewards_mean + jerbi_baseline_input_output_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"purple\")\n",
    "\n",
    "axs[0].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[0].legend(fontsize = 12)\n",
    "axs[0].set_ylim(0,500)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second Plot: Datareup\n",
    "# Plot rewards mean for jerbi_datareup\n",
    "axs[1].plot(jerbi_datareup_layer_rewards_mean, color=\"red\", label=\"Multi-Layer\")\n",
    "axs[1].plot(jerbi_datareup_input_rewards_mean, color=\"blue\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[1].plot(jerbi_datareup_output_rewards_mean, color=\"green\", label=\"Multi-Layer w/o Output Scaling\")\n",
    "axs[1].plot(jerbi_datareup_input_output_rewards_mean, color=\"purple\", label=\"Multi-Layer w/o Input & Output Scaling\")\n",
    "\n",
    "# Fill between for standard deviation for jerbi_datareup\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_layer_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_layer_rewards_mean - jerbi_datareup_layer_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_datareup_layer_rewards_mean + jerbi_datareup_layer_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_input_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_input_rewards_mean - jerbi_datareup_input_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_datareup_input_rewards_mean + jerbi_datareup_input_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_output_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_output_rewards_mean - jerbi_datareup_output_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_datareup_output_rewards_mean + jerbi_datareup_output_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"green\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_input_output_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_input_output_rewards_mean - jerbi_datareup_input_output_rewards_std, a_min=0, a_max=500),\n",
    "                       np.clip(jerbi_datareup_input_output_rewards_mean + jerbi_datareup_input_output_rewards_std, a_min=0, a_max=500),\n",
    "                       alpha=0.2, color=\"purple\")\n",
    "\n",
    "axs[1].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[1].legend(fontsize = 12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Cartpole-v1/TFQ/tfq_datareup_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "# Plot mean gradient norm\n",
    "axs[0].plot(jerbi_baseline_layer_norm_grads, color=\"red\", label=\"Single-Layer\")\n",
    "axs[0].plot(jerbi_baseline_input_norm_grads, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[0].plot(jerbi_datareup_layer_norm_grads, color=\"green\", label=\"Multi-Layer\")\n",
    "axs[0].plot(jerbi_datareup_input_norm_grads, color=\"purple\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[0].set_xlabel(\"Training Batch\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Gradient Norm\", fontsize = 12)\n",
    "axs[0].legend(fontsize = 12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot variance of gradient norm\n",
    "axs[1].plot(jerbi_baseline_layer_variance_grads, color=\"red\", label=\"Single-Layer\")\n",
    "axs[1].plot(jerbi_baseline_input_output_variance_grads, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[1].plot(jerbi_datareup_layer_variance_grads, color=\"green\", label=\"Multi-Layer\")\n",
    "axs[1].plot(jerbi_datareup_input_output_variance_grads, color=\"purple\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[1].set_xlabel(\"Training Batch\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Variance of the Gradient Norm\", fontsize = 12)\n",
    "axs[1].legend(fontsize = 12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Cartpole-v1/TFQ/tfq_cartpole_gradients.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_baseline_paths = [\n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_1layer\", \n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_1layer_input\", \n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_1layer_output\", \n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_1layer_input_output\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects for the updated paths\n",
    "jerbi_baseline_layer = Analysis(jerbi_baseline_paths[0])\n",
    "jerbi_baseline_input = Analysis(jerbi_baseline_paths[1])\n",
    "jerbi_baseline_output = Analysis(jerbi_baseline_paths[2])\n",
    "jerbi_baseline_input_output = Analysis(jerbi_baseline_paths[3])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_baseline_layer_rewards = jerbi_baseline_layer.get_moving_average(window_size=10)\n",
    "jerbi_baseline_input_rewards = jerbi_baseline_input.get_moving_average(window_size=10)\n",
    "jerbi_baseline_output_rewards = jerbi_baseline_output.get_moving_average(window_size=10)\n",
    "jerbi_baseline_input_output_rewards = jerbi_baseline_input_output.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_baseline_layer_rewards_mean = np.mean(jerbi_baseline_layer_rewards, axis=0)\n",
    "jerbi_baseline_input_rewards_mean = np.mean(jerbi_baseline_input_rewards, axis=0)\n",
    "jerbi_baseline_output_rewards_mean = np.mean(jerbi_baseline_output_rewards, axis=0)\n",
    "jerbi_baseline_input_output_rewards_mean = np.mean(jerbi_baseline_input_output_rewards, axis=0)\n",
    "\n",
    "jerbi_baseline_layer_rewards_std = np.std(jerbi_baseline_layer_rewards, axis=0)\n",
    "jerbi_baseline_input_rewards_std = np.std(jerbi_baseline_input_rewards, axis=0)\n",
    "jerbi_baseline_output_rewards_std = np.std(jerbi_baseline_output_rewards, axis=0)\n",
    "jerbi_baseline_input_output_rewards_std = np.std(jerbi_baseline_input_output_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_baseline_layer_norm_grads, jerbi_baseline_layer_variance_grads = jerbi_baseline_layer.compute_norm_and_variance()\n",
    "jerbi_baseline_input_norm_grads, jerbi_baseline_input_variance_grads = jerbi_baseline_input.compute_norm_and_variance()\n",
    "jerbi_baseline_output_norm_grads, jerbi_baseline_output_variance_grads = jerbi_baseline_output.compute_norm_and_variance()\n",
    "jerbi_baseline_input_output_norm_grads, jerbi_baseline_input_output_variance_grads = jerbi_baseline_input_output.compute_norm_and_variance()\n",
    "\n",
    "\n",
    "\n",
    "jerbi_datareup_paths = [\n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer\", \n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer_input\", \n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer_output\", \n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer_input_output\"\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects for the updated paths\n",
    "jerbi_datareup_layer = Analysis(jerbi_datareup_paths[0])\n",
    "jerbi_datareup_input = Analysis(jerbi_datareup_paths[1])\n",
    "jerbi_datareup_output = Analysis(jerbi_datareup_paths[2])\n",
    "jerbi_datareup_input_output = Analysis(jerbi_datareup_paths[3])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_datareup_layer_rewards = jerbi_datareup_layer.get_moving_average(window_size=10)\n",
    "jerbi_datareup_input_rewards = jerbi_datareup_input.get_moving_average(window_size=10)\n",
    "jerbi_datareup_output_rewards = jerbi_datareup_output.get_moving_average(window_size=10)\n",
    "jerbi_datareup_input_output_rewards = jerbi_datareup_input_output.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_datareup_layer_rewards_mean = np.mean(jerbi_datareup_layer_rewards, axis=0)\n",
    "jerbi_datareup_input_rewards_mean = np.mean(jerbi_datareup_input_rewards, axis=0)\n",
    "jerbi_datareup_output_rewards_mean = np.mean(jerbi_datareup_output_rewards, axis=0)\n",
    "jerbi_datareup_input_output_rewards_mean = np.mean(jerbi_datareup_input_output_rewards, axis=0)\n",
    "\n",
    "jerbi_datareup_layer_rewards_std = np.std(jerbi_datareup_layer_rewards, axis=0)\n",
    "jerbi_datareup_input_rewards_std = np.std(jerbi_datareup_input_rewards, axis=0)\n",
    "jerbi_datareup_output_rewards_std = np.std(jerbi_datareup_output_rewards, axis=0)\n",
    "jerbi_datareup_input_output_rewards_std = np.std(jerbi_datareup_input_output_rewards, axis=0)\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_dataeup_layer_norm_grads, jerbi_ddataeup_layer_variance_grads = jerbi_datareup_layer.compute_norm_and_variance()\n",
    "jerbi_datareup_input_norm_grads, jerbi_datareup_input_variance_grads = jerbi_datareup_input.compute_norm_and_variance()\n",
    "jerbi_dataeup_output_norm_grads, jerbi_datareup_output_variance_grads = jerbi_datareup_output.compute_norm_and_variance()\n",
    "jerbi_datareup_input_output_norm_grads, jerbi_datareup_input_output_variance_grads = jerbi_datareup_input_output.compute_norm_and_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "# First Plot: Baseline\n",
    "# Plot rewards mean for jerbi_baseline\n",
    "axs[0].plot(jerbi_baseline_layer_rewards_mean, color=\"red\", label=\"Single-Layer\")\n",
    "axs[0].plot(jerbi_baseline_input_rewards_mean, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[0].plot(jerbi_baseline_output_rewards_mean, color=\"green\", label=\"Single-Layer w/o Output Scaling\")\n",
    "axs[0].plot(jerbi_baseline_input_output_rewards_mean, color=\"purple\", label=\"Single-Layer w/o Input & Output Scaling\")\n",
    "\n",
    "# Fill between for standard deviation for jerbi_baseline\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_layer_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_layer_rewards_mean - jerbi_baseline_layer_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_baseline_layer_rewards_mean + jerbi_baseline_layer_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_input_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_input_rewards_mean - jerbi_baseline_input_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_baseline_input_rewards_mean + jerbi_baseline_input_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_output_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_output_rewards_mean - jerbi_baseline_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_baseline_output_rewards_mean + jerbi_baseline_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"green\")\n",
    "axs[0].fill_between(np.arange(len(jerbi_baseline_input_output_rewards_mean)), \n",
    "                       np.clip(jerbi_baseline_input_output_rewards_mean - jerbi_baseline_input_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_baseline_input_output_rewards_mean + jerbi_baseline_input_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"purple\")\n",
    "\n",
    "axs[0].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[0].set_ylim(-500,0)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].legend(fontsize = 12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second Plot: Datareup\n",
    "# Plot rewards mean for jerbi_datareup\n",
    "axs[1].plot(jerbi_datareup_layer_rewards_mean, color=\"red\", label=\"Multi-Layer\")\n",
    "axs[1].plot(jerbi_datareup_input_rewards_mean, color=\"blue\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[1].plot(jerbi_datareup_output_rewards_mean, color=\"green\", label=\"Multi-Layer w/o Output Scaling\")\n",
    "axs[1].plot(jerbi_datareup_input_output_rewards_mean, color=\"purple\", label=\"Multi-Layer w/o Input & Output Scaling\")\n",
    "\n",
    "# Fill between for standard deviation for jerbi_datareup\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_layer_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_layer_rewards_mean - jerbi_datareup_layer_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_datareup_layer_rewards_mean + jerbi_datareup_layer_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"red\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_input_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_input_rewards_mean - jerbi_datareup_input_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_datareup_input_rewards_mean + jerbi_datareup_input_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"blue\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_output_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_output_rewards_mean - jerbi_datareup_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_datareup_output_rewards_mean + jerbi_datareup_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"green\")\n",
    "axs[1].fill_between(np.arange(len(jerbi_datareup_input_output_rewards_mean)), \n",
    "                       np.clip(jerbi_datareup_input_output_rewards_mean - jerbi_datareup_input_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       np.clip(jerbi_datareup_input_output_rewards_mean + jerbi_datareup_input_output_rewards_std, a_min=-500, a_max=0),\n",
    "                       alpha=0.2, color=\"purple\")\n",
    "\n",
    "axs[1].set_xlabel(\"Episode\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Mean Return\", fontsize = 12)\n",
    "axs[1].set_ylim(-500,0)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].legend(fontsize = 12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/TFQ/tfq_datareup_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "# Plot mean gradient norm\n",
    "axs[0].plot(jerbi_baseline_layer_norm_grads, color=\"red\", label=\"Single-Layer\")\n",
    "axs[0].plot(jerbi_baseline_input_norm_grads, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[0].plot(jerbi_datareup_layer_norm_grads, color=\"green\", label=\"Multi-Layer\")\n",
    "axs[0].plot(jerbi_datareup_input_norm_grads, color=\"purple\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[0].set_xlabel(\"Training Batch\", fontsize = 12)\n",
    "axs[0].set_ylabel(\"Mean Gradient Norm\", fontsize = 12)\n",
    "axs[0].legend(fontsize = 12)\n",
    "axs[0].xaxis.set_tick_params(labelsize=12)\n",
    "axs[0].yaxis.set_tick_params(labelsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot variance of gradient norm\n",
    "axs[1].plot(jerbi_baseline_layer_variance_grads, color=\"red\", label=\"Single-Layer\")\n",
    "axs[1].plot(jerbi_baseline_input_output_variance_grads, color=\"blue\", label=\"Single-Layer w/o Input Scaling\")\n",
    "axs[1].plot(jerbi_datareup_layer_variance_grads, color=\"green\", label=\"Multi-Layer\")\n",
    "axs[1].plot(jerbi_datareup_input_output_variance_grads, color=\"purple\", label=\"Multi-Layer w/o Input Scaling\")\n",
    "axs[1].set_xlabel(\"Training Batch\", fontsize = 12)\n",
    "axs[1].set_ylabel(\"Variance of the Gradient Norm\", fontsize = 12)\n",
    "axs[1].legend(fontsize = 12)\n",
    "axs[1].xaxis.set_tick_params(labelsize=12)\n",
    "axs[1].yaxis.set_tick_params(labelsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/TFQ/tfq_gradients_acrobot.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFQ beta tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_paths = [\n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer\",\n",
    "    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer_beta\",\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "jerbi = Analysis(jerbi_paths[0])\n",
    "jerbi_beta = Analysis(jerbi_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_rewards = jerbi.get_moving_average(window_size=10)\n",
    "jerbi_beta_rewards = jerbi_beta.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_rewards_mean = np.mean(jerbi_rewards, axis=0)\n",
    "jerbi_beta_rewards_mean = np.mean(jerbi_beta_rewards, axis=0)\n",
    "jerbi_rewards_std = np.std(jerbi_rewards, axis=0)\n",
    "jerbi_beta_rewards_std = np.std(jerbi_beta_rewards, axis=0)\n",
    "\n",
    "# Compute mean loss\n",
    "jerbi_loss = jerbi.compute_mean_loss()\n",
    "jerbi_beta_loss = jerbi_beta.compute_mean_loss()\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_norm_grads, jerbi_variance_grads = jerbi.compute_norm_and_variance()\n",
    "jerbi_beta_norm_grads, jerbi_beta_variance_grads = jerbi_beta.compute_norm_and_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot rewards mean\n",
    "plt.plot(jerbi_rewards_mean, color=\"red\", label=\"Multi-Layer\")\n",
    "plt.plot(jerbi_beta_rewards_mean, color=\"blue\", label=\"Multi-Layer w/ Beta Scheduling\")\n",
    "\n",
    "# Fill between for standard deviation\n",
    "plt.fill_between(np.arange(len(jerbi_rewards_mean)), \n",
    "                 np.clip(jerbi_rewards_mean - jerbi_rewards_std, a_min=0, a_max=500),\n",
    "                 np.clip(jerbi_rewards_mean + jerbi_rewards_std, a_min=0, a_max=500),\n",
    "                 alpha=0.2, color=\"red\")\n",
    "\n",
    "plt.fill_between(np.arange(len(jerbi_beta_rewards_mean)), \n",
    "                 np.clip(jerbi_beta_rewards_mean - jerbi_beta_rewards_std, a_min=0, a_max=500),\n",
    "                 np.clip(jerbi_beta_rewards_mean + jerbi_beta_rewards_std, a_min=0, a_max=500),\n",
    "                 alpha=0.2, color=\"blue\")\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)  # Set x-axis tick size\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)  # Set y-axis tick size\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/TFQ/tfq_beta_cartpole.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerbi_paths = [\n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer\",\n",
    "    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer_beta\",\n",
    "]\n",
    "\n",
    "# Initialize Analysis objects\n",
    "jerbi = Analysis(jerbi_paths[0])\n",
    "jerbi_beta = Analysis(jerbi_paths[1])\n",
    "\n",
    "# Calculate moving averages for rewards\n",
    "jerbi_rewards = jerbi.get_moving_average(window_size=10)\n",
    "jerbi_beta_rewards = jerbi_beta.get_moving_average(window_size=10)\n",
    "\n",
    "# Compute mean and std for rewards\n",
    "jerbi_rewards_mean = np.mean(jerbi_rewards, axis=0)\n",
    "jerbi_beta_rewards_mean = np.mean(jerbi_beta_rewards, axis=0)\n",
    "jerbi_rewards_std = np.std(jerbi_rewards, axis=0)\n",
    "jerbi_beta_rewards_std = np.std(jerbi_beta_rewards, axis=0)\n",
    "\n",
    "# Compute mean loss\n",
    "jerbi_loss = jerbi.compute_mean_loss()\n",
    "jerbi_beta_loss = jerbi_beta.compute_mean_loss()\n",
    "\n",
    "# Calculate gradients and their variance\n",
    "jerbi_norm_grads, jerbi_variance_grads = jerbi.compute_norm_and_variance()\n",
    "jerbi_beta_norm_grads, jerbi_beta_variance_grads = jerbi_beta.compute_norm_and_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot rewards mean\n",
    "plt.plot(jerbi_rewards_mean, color=\"red\", label=\"Multi-Layer\")\n",
    "plt.plot(jerbi_beta_rewards_mean, color=\"blue\", label=\"Multi-Layer w/ Beta Scheduling\")\n",
    "\n",
    "# Fill between for standard deviation\n",
    "plt.fill_between(np.arange(len(jerbi_rewards_mean)), \n",
    "                 np.clip(jerbi_rewards_mean - jerbi_rewards_std, a_min=-500, a_max=0),\n",
    "                 np.clip(jerbi_rewards_mean + jerbi_rewards_std, a_min=-500, a_max=0),\n",
    "                 alpha=0.2, color=\"red\")\n",
    "\n",
    "plt.fill_between(np.arange(len(jerbi_beta_rewards_mean)), \n",
    "                 np.clip(jerbi_beta_rewards_mean - jerbi_beta_rewards_std, a_min=-500, a_max=0),\n",
    "                 np.clip(jerbi_beta_rewards_mean + jerbi_beta_rewards_std, a_min=-500, a_max=0),\n",
    "                 alpha=0.2, color=\"blue\")\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.ylim(-500,0)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)  # Set x-axis tick size\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)  # Set y-axis tick size\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/TFQ/tfq_beta_acrobot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_paths= [\"../../../../data/CartPole-v1/JERBI/JerbiModel_4qubits_5layer\",\n",
    "                    \"../../../../data/CartPole-v1/TFQ/TfqTutorial_4qubits_5layer\",\n",
    "                    \"../../../../data/CartPole-v1/UQC/UQC_FullEnc_4qubits\"\n",
    "]\n",
    "\n",
    "jerbi = Analysis(best_models_paths[0])\n",
    "tfq = Analysis(best_models_paths[1])\n",
    "uqc = Analysis(best_models_paths[2])\n",
    "\n",
    "jerbi_rewards = jerbi.get_moving_average(window_size=10)\n",
    "tfq_rewards = tfq.get_moving_average(window_size=10)\n",
    "uqc_rewards = uqc.get_moving_average(window_size=10)\n",
    "\n",
    "\n",
    "jerbi_rewards_mean = np.mean(jerbi_rewards, axis=0)\n",
    "tfq_rewards_mean = np.mean(tfq_rewards, axis=0)\n",
    "uqc_rewards_mean = np.mean(uqc_rewards, axis=0)\n",
    "\n",
    "\n",
    "jerbi_rewards_std = np.std(jerbi_rewards, axis=0)\n",
    "tfq_rewards_std = np.std(tfq_rewards, axis=0)\n",
    "uqc_rewards_std = np.std(uqc_rewards, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot rewards mean\n",
    "plt.plot(jerbi_rewards_mean, color=\"red\", label=\"Multi-Layer Jerbi\")\n",
    "plt.plot(tfq_rewards_mean, color=\"blue\", label=\"Multi-Layer TFQ\")\n",
    "plt.plot(uqc_rewards_mean, color=\"green\", label=\"Four-Qubit UQC\")\n",
    "\n",
    "# Fill between for standard deviation\n",
    "plt.fill_between(np.arange(len(jerbi_rewards_mean)), \n",
    "                 np.clip(jerbi_rewards_mean - jerbi_rewards_std, a_min=0, a_max=500),\n",
    "                 np.clip(jerbi_rewards_mean + jerbi_rewards_std, a_min=0, a_max=500),\n",
    "                 alpha=0.2, color=\"red\")\n",
    "\n",
    "plt.fill_between(np.arange(len(tfq_rewards_mean)), \n",
    "                 np.clip(tfq_rewards_mean - tfq_rewards_std, a_min=0, a_max=500),\n",
    "                 np.clip(tfq_rewards_mean + tfq_rewards_std, a_min=0, a_max=500),\n",
    "                 alpha=0.2, color=\"blue\")\n",
    "\n",
    "plt.fill_between(np.arange(len(uqc_rewards_mean)), \n",
    "                 np.clip(uqc_rewards_mean - uqc_rewards_std, a_min=0, a_max=500),\n",
    "                 np.clip(uqc_rewards_mean + uqc_rewards_std, a_min=0, a_max=500),\n",
    "                 alpha=0.2, color=\"green\")\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)  # Set x-axis tick size\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)  # Set y-axis tick size\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/CartPole-v1/best_models_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_paths= [\"../../../../data/Acrobot-v1/JERBI/JerbiModel_4qubits_5layer\",\n",
    "                    \"../../../../data/Acrobot-v1/TFQ/TfqTutorial_4qubits_5layer\",\n",
    "                    \"../../../../data/Acrobot-v1/UQC/UQC_FullEnc_4qubits\"\n",
    "]\n",
    "\n",
    "jerbi = Analysis(best_models_paths[0])\n",
    "tfq = Analysis(best_models_paths[1])\n",
    "uqc = Analysis(best_models_paths[2])\n",
    "\n",
    "jerbi_rewards = jerbi.get_moving_average(window_size=10)\n",
    "tfq_rewards = tfq.get_moving_average(window_size=10)\n",
    "uqc_rewards = uqc.get_moving_average(window_size=10)\n",
    "\n",
    "\n",
    "jerbi_rewards_mean = np.mean(jerbi_rewards, axis=0)\n",
    "tfq_rewards_mean = np.mean(tfq_rewards, axis=0)\n",
    "uqc_rewards_mean = np.mean(uqc_rewards, axis=0)\n",
    "\n",
    "\n",
    "jerbi_rewards_std = np.std(jerbi_rewards, axis=0)\n",
    "tfq_rewards_std = np.std(tfq_rewards, axis=0)\n",
    "uqc_rewards_std = np.std(uqc_rewards, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot rewards mean\n",
    "plt.plot(jerbi_rewards_mean, color=\"red\", label=\"Multi-Layer Jerbi\")\n",
    "plt.plot(tfq_rewards_mean, color=\"blue\", label=\"Multi-Layer TFQ\")\n",
    "plt.plot(uqc_rewards_mean, color=\"green\", label=\"Four-Qubit UQC\")\n",
    "\n",
    "# Fill between for standard deviation\n",
    "plt.fill_between(np.arange(len(jerbi_rewards_mean)), \n",
    "                 np.clip(jerbi_rewards_mean - jerbi_rewards_std, a_min=-500, a_max=0),\n",
    "                 np.clip(jerbi_rewards_mean + jerbi_rewards_std, a_min=-500, a_max=0),\n",
    "                 alpha=0.2, color=\"red\")\n",
    "\n",
    "plt.fill_between(np.arange(len(tfq_rewards_mean)), \n",
    "                 np.clip(tfq_rewards_mean - tfq_rewards_std, a_min=-500, a_max=0),\n",
    "                 np.clip(tfq_rewards_mean + tfq_rewards_std, a_min=-500, a_max=0),\n",
    "                 alpha=0.2, color=\"blue\")\n",
    "\n",
    "plt.fill_between(np.arange(len(uqc_rewards_mean)), \n",
    "                 np.clip(uqc_rewards_mean - uqc_rewards_std, a_min=-500, a_max=0),\n",
    "                 np.clip(uqc_rewards_mean + uqc_rewards_std, a_min=-500, a_max=0),\n",
    "                 alpha=0.2, color=\"green\")\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel(\"Episode\", fontsize = 12)\n",
    "plt.ylabel(\"Mean Return\", fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.gca().xaxis.set_tick_params(labelsize=12)  # Set x-axis tick size\n",
    "plt.gca().yaxis.set_tick_params(labelsize=12)  # Set y-axis tick size\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"../../../../data/Acrobot-v1/best_models_cartpole.pdf\", format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
